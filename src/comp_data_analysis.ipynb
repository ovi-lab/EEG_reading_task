{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt6.QtCore\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt6\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use qt backend for matplotlab to use interactive mne plots\n",
    "%matplotlib qt\n",
    "\n",
    "import mne \n",
    "import analysis.processing\n",
    "import pandas as pd\n",
    "import csv \n",
    "import os\n",
    "from config import Config\n",
    "configObj = Config()\n",
    "from mne_connectivity import spectral_connectivity_time\n",
    "import numpy as np\n",
    "configss = configObj.getConfigSnapshot()\n",
    "from tqdm import tqdm\n",
    "import tools.helpers\n",
    "from scipy import stats\n",
    "\n",
    "mne.set_log_level(verbose='WARNING', return_old_level=False, add_frames=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 200 # 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Participant Data: 100%|██████████| 24/24 [00:00<00:00, 786.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found duplicate entries for some ParticipantID and BlockType combinations. Aggregating by mean.\n",
      "Shapiro-Wilk Test for BlockType 'D': p-value = 0.1389\n",
      "Shapiro-Wilk Test for BlockType 'ND': p-value = 0.0068\n",
      "\n",
      "Overall Normality Assumption Met: False\n",
      "\n",
      "Data is not normally distributed. Performing pairwise Wilcoxon signed-rank tests.\n",
      "\n",
      "Pairwise Wilcoxon Signed-Rank Test Results (Bonferroni Adjusted):\n",
      "  Block Type 1 Block Type 2  Statistic (Wilcoxon W)   P-value  \\\n",
      "0            D           ND                    67.5  0.054613   \n",
      "\n",
      "   Effect Size (r)  Adjusted P-value  \n",
      "0         0.312952          0.054613  \n",
      "\n",
      "Descriptive Statistics:\n",
      "  BlockType  Mean Correct  Std Deviation\n",
      "0         D      0.687500       0.172454\n",
      "1        ND      0.774306       0.135666\n",
      "\n",
      "Pairwise Wilcoxon Signed-Rank Test Results:\n",
      "  Block Type 1 Block Type 2  Statistic (Wilcoxon W)   P-value  \\\n",
      "0            D           ND                    67.5  0.054613   \n",
      "\n",
      "   Effect Size (r)  Adjusted P-value  \n",
      "0         0.312952          0.054613  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\erangad\\AppData\\Local\\Temp\\ipykernel_26168\\2608963028.py:208: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=('ci', 95)` for the same effect.\n",
      "\n",
      "  sns.barplot(x='BlockType', y='Correct', data=df, ci= 95, palette='viridis')\n",
      "C:\\Users\\erangad\\AppData\\Local\\Temp\\ipykernel_26168\\2608963028.py:208: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='BlockType', y='Correct', data=df, ci= 95, palette='viridis')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pingouin as pg\n",
    "from scipy.stats import shapiro, wilcoxon\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure 'configss' is defined appropriately\n",
    "# Example:\n",
    "# configss = {\n",
    "#     'root': '/path/to/data',\n",
    "#     'data_qa': 'qa_data_directory'\n",
    "# }\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Data Loading and Preparation\n",
    "# -----------------------------\n",
    "\n",
    "# List of participant IDs excluding certain ones\n",
    "participant_ids = [el for el in range(1, 32) if el not in [14, 5, 13, 16, 17, 20, 31]]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "for pnum in tqdm(participant_ids, desc=\"Loading Participant Data\"):\n",
    "    participant_data_path = f\"{pnum}.csv\"\n",
    "    path_qa = os.path.join(configss['root'], configss['data_qa'], participant_data_path)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(path_qa):\n",
    "        print(f\"Warning: File {path_qa} does not exist. Skipping participant {pnum}.\")\n",
    "        continue\n",
    "    \n",
    "    # Read the data for the current participant\n",
    "    participant_df = pd.read_csv(path_qa)\n",
    "    \n",
    "    # Add a column for ParticipantID\n",
    "    participant_df['ParticipantID'] = pnum\n",
    "    \n",
    "    # Append to the list\n",
    "    dataframes.append(participant_df)\n",
    "\n",
    "# Concatenate all participant DataFrames into one DataFrame\n",
    "if not dataframes:\n",
    "    raise ValueError(\"No participant data loaded. Please check the file paths and existence.\")\n",
    "\n",
    "df = pd.concat(dataframes, axis=0).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Function to replace outliers with median\n",
    "def replace_outliers(df, group_col, value_col):\n",
    "    df_copy = df.copy()\n",
    "    medians = df.groupby(group_col)[value_col].transform('median')\n",
    "    \n",
    "    Q1 = df[value_col].quantile(0.25)\n",
    "    Q3 = df[value_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Replace outliers with median\n",
    "    df_copy.loc[(df[value_col] < lower_bound) | (df[value_col] > upper_bound), value_col] = medians\n",
    "    return df_copy\n",
    "\n",
    "# Replace outliers in the combined data\n",
    "df = replace_outliers(df, 'BlockType', 'Correct')\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Data Aggregation\n",
    "# -----------------------------\n",
    "\n",
    "# Check for multiple entries per ParticipantID and BlockType\n",
    "duplicates = df.duplicated(subset=['ParticipantID', 'BlockType'])\n",
    "if duplicates.any():\n",
    "    print(\"Found duplicate entries for some ParticipantID and BlockType combinations. Aggregating by mean.\")\n",
    "    # Aggregate by mean to have one 'Correct' score per ParticipantID per BlockType\n",
    "    df = df.groupby(['ParticipantID', 'BlockType'], as_index=False)['Correct'].mean()\n",
    "\n",
    "# Verify that each participant has all BlockTypes\n",
    "expected_block_types = df['BlockType'].unique()\n",
    "participants_block_types = df.groupby('ParticipantID')['BlockType'].nunique()\n",
    "\n",
    "missing_blocks = participants_block_types[participants_block_types != len(expected_block_types)]\n",
    "if not missing_blocks.empty:\n",
    "    print(\"The following ParticipantIDs are missing some BlockTypes and will be excluded:\")\n",
    "    print(missing_blocks[missing_blocks != len(expected_block_types)].index.tolist())\n",
    "    # Exclude participants with incomplete data\n",
    "    df = df[~df['ParticipantID'].isin(missing_blocks.index.tolist())]\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Normality Testing\n",
    "# -----------------------------\n",
    "\n",
    "# Perform Shapiro-Wilk test for normality on 'Correct' scores within each BlockType\n",
    "normality_results = {}\n",
    "for block_type in df['BlockType'].unique():\n",
    "    stat, p = shapiro(df[df['BlockType'] == block_type]['Correct'])\n",
    "    normality_results[block_type] = p\n",
    "    print(f\"Shapiro-Wilk Test for BlockType '{block_type}': p-value = {p:.4f}\")\n",
    "\n",
    "# Determine overall normality\n",
    "is_normal = all(p > 0.05 for p in normality_results.values())\n",
    "print(f\"\\nOverall Normality Assumption Met: {is_normal}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Statistical Analysis\n",
    "# -----------------------------\n",
    "\n",
    "if is_normal:\n",
    "    # -----------------------------\n",
    "    # 4a. Repeated Measures ANOVA\n",
    "    # -----------------------------\n",
    "    print(\"\\nData is normally distributed. Performing Repeated Measures ANOVA.\")\n",
    "    \n",
    "    # Perform Repeated Measures ANOVA using pingouin\n",
    "    aov = pg.rm_anova(dv='Correct', within='BlockType', subject='ParticipantID', data=df, detailed=True)\n",
    "    print(\"\\nANOVA Results:\")\n",
    "    print(aov)\n",
    "    \n",
    "    # Extract F-statistic and partial eta squared\n",
    "    f_stat = aov.loc[aov['Source'] == 'BlockType', 'F'].values[0]\n",
    "    p_value = aov.loc[aov['Source'] == 'BlockType', 'p-unc'].values[0]\n",
    "    partial_eta_sq = aov.loc[aov['Source'] == 'BlockType', 'np2'].values[0]\n",
    "    \n",
    "    print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "    print(f\"P-value: {p_value:.4f}\")\n",
    "    print(f\"Partial Eta Squared: {partial_eta_sq:.4f}\")\n",
    "    \n",
    "    # Effect size is already provided as partial_eta_sq\n",
    "    effect_size = partial_eta_sq\n",
    "    \n",
    "else:\n",
    "    # -----------------------------\n",
    "    # 4b. Wilcoxon Signed-Rank Test\n",
    "    # -----------------------------\n",
    "    print(\"\\nData is not normally distributed. Performing pairwise Wilcoxon signed-rank tests.\")\n",
    "    \n",
    "    block_types = sorted(df['BlockType'].unique())  # Sort for consistent pairing\n",
    "    wilcoxon_results = []\n",
    "    \n",
    "    # Pivot the data to have one row per ParticipantID and columns for each BlockType\n",
    "    pivot_df = df.pivot(index='ParticipantID', columns='BlockType', values='Correct')\n",
    "    \n",
    "    # Identify all unique pairs of BlockTypes for pairwise comparisons\n",
    "    from itertools import combinations\n",
    "    block_type_pairs = list(combinations(block_types, 2))\n",
    "    \n",
    "    for pair in block_type_pairs:\n",
    "        bt1, bt2 = pair\n",
    "        data1 = pivot_df[bt1]\n",
    "        data2 = pivot_df[bt2]\n",
    "        \n",
    "        # Ensure no missing data\n",
    "        paired_data = pivot_df[[bt1, bt2]].dropna()\n",
    "        data1 = paired_data[bt1]\n",
    "        data2 = paired_data[bt2]\n",
    "        \n",
    "        # Perform Wilcoxon signed-rank test\n",
    "        stat, p = wilcoxon(data1, data2, alternative='two-sided')\n",
    "        \n",
    "        # Compute rank-biserial correlation as effect size\n",
    "        # Using formula: r = Z / sqrt(N)\n",
    "        # However, scipy's wilcoxon does not return Z, so we use pingouin's compute_effsize\n",
    "        # Alternatively, use the formula: r = (W - (n*(n+1)/4)) / sqrt(n*(n+1)*(2*n+1)/24)\n",
    "        # But it's simpler to use pingouin\n",
    "        \n",
    "        # Compute effect size using pingouin's compute_effsize\n",
    "        # Requires 'paired=True' and 'eftype' parameter\n",
    "        # Since data is paired, we pass data1 and data2 directly\n",
    "        # 'rank_biserial' is one option, but pingouin may not support it directly\n",
    "        # Instead, use 'r' which is rank correlation\n",
    "        effsize = pg.compute_effsize(paired_data[bt1], paired_data[bt2], paired=True, eftype='r')\n",
    "        \n",
    "        wilcoxon_results.append({\n",
    "            'Block Type 1': bt1,\n",
    "            'Block Type 2': bt2,\n",
    "            'Statistic (Wilcoxon W)': stat,\n",
    "            'P-value': p,\n",
    "            'Effect Size (r)': effsize\n",
    "        })\n",
    "    \n",
    "    # Convert results to DataFrame\n",
    "    wilcoxon_df = pd.DataFrame(wilcoxon_results)\n",
    "    \n",
    "    # Adjust p-values for multiple comparisons using Bonferroni correction\n",
    "    wilcoxon_df['Adjusted P-value'] = wilcoxon_df['P-value'] * len(block_type_pairs)\n",
    "    wilcoxon_df['Adjusted P-value'] = wilcoxon_df['Adjusted P-value'].apply(lambda x: min(x, 1.0))\n",
    "    \n",
    "    print(\"\\nPairwise Wilcoxon Signed-Rank Test Results (Bonferroni Adjusted):\")\n",
    "    print(wilcoxon_df)\n",
    "\n",
    "    # For visualization, you might want to annotate significant differences\n",
    "    # This can be done using statistical annotations libraries like statannot or manually\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Visualization\n",
    "# -----------------------------\n",
    "\n",
    "# Calculate means, counts, stds for each BlockType\n",
    "stats_df = df.groupby('BlockType')['Correct'].agg(['mean', 'count', 'std']).reset_index()\n",
    "stats_df['sem'] = stats_df['std'] / np.sqrt(stats_df['count'])  # Standard Error of Mean\n",
    "stats_df['ci95'] = 1.96 * stats_df['sem']  # 95% Confidence Interval\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='BlockType', y='Correct', data=df, ci= 95, palette='viridis')\n",
    "\n",
    "# Adding error bars manually for more control\n",
    "# plt.errorbar(x=np.arange(len(stats_df)), y=stats_df['mean'], yerr=stats_df['ci95'],\n",
    "            #  fmt='none', c='black', capsize=10)\n",
    "\n",
    "# Adding titles and labels\n",
    "if is_normal:\n",
    "    plt.title(f'Q&A Accuracy by Block Type')\n",
    "else:\n",
    "    plt.title('Q&A Accuracy by Block Type')\n",
    "plt.xlabel('Block Type')\n",
    "plt.ylabel('Accuracy (Proportion of Correct Answers)')\n",
    "\n",
    "# Improve layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Descriptive Statistics and Effect Sizes\n",
    "# -----------------------------\n",
    "\n",
    "if is_normal:\n",
    "    # Display descriptive statistics and effect size\n",
    "    display_df = stats_df[['BlockType', 'mean', 'std']]\n",
    "    display_df = display_df.rename(columns={'mean': 'Mean Correct', 'std': 'Std Deviation'})\n",
    "    display_df['Partial Eta Squared'] = partial_eta_sq\n",
    "    print(\"\\nDescriptive Statistics and Effect Size:\")\n",
    "    print(display_df)\n",
    "else:\n",
    "    # Display Wilcoxon test results with descriptive statistics\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    print(stats_df[['BlockType', 'mean', 'std']].rename(columns={'mean': 'Mean Correct', 'std': 'Std Deviation'}))\n",
    "    print(\"\\nPairwise Wilcoxon Signed-Rank Test Results:\")\n",
    "    print(wilcoxon_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
