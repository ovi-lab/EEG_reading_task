{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt6.QtCore\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt5\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file to check its contents\n",
    "file_path = 'classification_results_3_fbcsp.csv'\n",
    "classification_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file to check its contents\n",
    "file_path = 'classification_results_4_fbcsp_like_muse.csv'\n",
    "classification_data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduced analysis against full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the uploaded CSV files\n",
    "file_1_path = 'classification_results_4_fbcsp_like_muse.csv'\n",
    "file_3_path = 'classification_results_3_fbcsp.csv'\n",
    "\n",
    "# Reading the CSV files to explore their structure\n",
    "data_reduced_channels = pd.read_csv(file_1_path)\n",
    "data_full_channels_new = pd.read_csv(file_3_path)\n",
    "\n",
    "# Extracting relevant columns and adding a new column to distinguish between reduced and full channels\n",
    "data_reduced_channels_plot = data_reduced_channels[['classifier', 'mean_accuracy']].copy()\n",
    "data_reduced_channels_plot['Channel Type'] = 'Reduced'\n",
    "\n",
    "data_full_channels_new_plot = data_full_channels_new[['classifier', 'mean_accuracy']].copy()\n",
    "data_full_channels_new_plot['Channel Type'] = 'Full'\n",
    "\n",
    "# Combining the reduced channels data with the corrected full channels data for plotting\n",
    "combined_data_corrected = pd.concat([data_reduced_channels_plot, data_full_channels_new_plot], ignore_index=True)\n",
    "\n",
    "# Plotting the accuracy for each classifier grouped by channel type\n",
    "plt.figure(figsize=(12, 6))\n",
    "for channel_type, group_data in combined_data_corrected.groupby('Channel Type'):\n",
    "    plt.bar(group_data['classifier'], group_data['mean_accuracy'], alpha=0.6, label=channel_type)\n",
    "\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Classifier Accuracy for Reduced and Full Channel Analysis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Channel Type')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the uploaded CSV files\n",
    "file_1_path = 'classification_results_4_fbcsp_like_muse.csv'\n",
    "file_3_path = 'classification_results_3_fbcsp.csv'\n",
    "\n",
    "# Reading the CSV files\n",
    "data_reduced_channels = pd.read_csv(file_1_path)\n",
    "data_full_channels_new = pd.read_csv(file_3_path)\n",
    "\n",
    "# Extract relevant columns for plotting\n",
    "data_reduced_channels_plot = data_reduced_channels[['classifier', 'mean_accuracy']].copy()\n",
    "data_reduced_channels_plot['Channel Type'] = 'Reduced'\n",
    "\n",
    "data_full_channels_plot = data_full_channels_new[['classifier', 'mean_accuracy']].copy()\n",
    "data_full_channels_plot['Channel Type'] = 'Full'\n",
    "\n",
    "# Combine both datasets\n",
    "combined_data = pd.concat([data_reduced_channels_plot, data_full_channels_plot], ignore_index=True)\n",
    "\n",
    "# Find the common classifiers in both datasets\n",
    "common_classifiers = np.intersect1d(data_reduced_channels_plot['classifier'].unique(), data_full_channels_plot['classifier'].unique())\n",
    "\n",
    "# Filter the data to include only the common classifiers\n",
    "reduced_data_filtered = data_reduced_channels_plot[data_reduced_channels_plot['classifier'].isin(common_classifiers)]\n",
    "full_data_filtered = data_full_channels_plot[data_full_channels_plot['classifier'].isin(common_classifiers)]\n",
    "\n",
    "# Group by classifiers to aggregate mean accuracy\n",
    "reduced_data_aggregated = reduced_data_filtered.groupby('classifier')['mean_accuracy'].mean().reset_index()\n",
    "full_data_aggregated = full_data_filtered.groupby('classifier')['mean_accuracy'].mean().reset_index()\n",
    "\n",
    "# Sort classifiers for consistency in plotting\n",
    "reduced_data_aggregated.sort_values(by='classifier', inplace=True)\n",
    "full_data_aggregated.sort_values(by='classifier', inplace=True)\n",
    "\n",
    "# Extract the sorted list of classifiers\n",
    "classifiers = reduced_data_aggregated['classifier'].values\n",
    "positions = np.arange(len(classifiers))\n",
    "bar_width = 0.35\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot for reduced channel data\n",
    "plt.bar(positions - bar_width/2, reduced_data_aggregated['mean_accuracy'], bar_width, label='Reduced', alpha=0.6)\n",
    "\n",
    "# Plot for full channel data\n",
    "plt.bar(positions + bar_width/2, full_data_aggregated['mean_accuracy'], bar_width, label='Full', alpha=0.6)\n",
    "\n",
    "# Customizing the plot\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Classifier Accuracy for Reduced and Full Channel Analysis (Side by Side)')\n",
    "plt.xticks(positions, classifiers, rotation=45)\n",
    "plt.legend(title='Channel Type')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's revise the code to include error bars using the standard deviation (std_accuracy) for each classifier.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the uploaded CSV files\n",
    "file_1_path = 'classification_results_4_fbcsp_like_muse.csv'\n",
    "file_3_path = 'classification_results_3_fbcsp.csv'\n",
    "\n",
    "# Reading the CSV files\n",
    "data_reduced_channels = pd.read_csv(file_1_path)\n",
    "data_full_channels_new = pd.read_csv(file_3_path)\n",
    "\n",
    "# Extract relevant columns for plotting\n",
    "data_reduced_channels_plot = data_reduced_channels[['classifier', 'mean_accuracy', 'std_accuracy']].copy()\n",
    "data_reduced_channels_plot['Channel Type'] = 'Reduced'\n",
    "\n",
    "data_full_channels_plot = data_full_channels_new[['classifier', 'mean_accuracy', 'std_accuracy']].copy()\n",
    "data_full_channels_plot['Channel Type'] = 'Full'\n",
    "\n",
    "# Combine both datasets\n",
    "combined_data = pd.concat([data_reduced_channels_plot, data_full_channels_plot], ignore_index=True)\n",
    "\n",
    "# Find the common classifiers in both datasets\n",
    "common_classifiers = np.intersect1d(data_reduced_channels_plot['classifier'].unique(), data_full_channels_plot['classifier'].unique())\n",
    "\n",
    "# Filter the data to include only the common classifiers\n",
    "reduced_data_filtered = data_reduced_channels_plot[data_reduced_channels_plot['classifier'].isin(common_classifiers)]\n",
    "full_data_filtered = data_full_channels_plot[data_full_channels_plot['classifier'].isin(common_classifiers)]\n",
    "\n",
    "# Group by classifiers to aggregate mean accuracy and standard deviation\n",
    "reduced_data_aggregated = reduced_data_filtered.groupby('classifier').agg({'mean_accuracy': 'mean', 'std_accuracy': 'mean'}).reset_index()\n",
    "full_data_aggregated = full_data_filtered.groupby('classifier').agg({'mean_accuracy': 'mean', 'std_accuracy': 'mean'}).reset_index()\n",
    "\n",
    "# Sort classifiers for consistency in plotting\n",
    "reduced_data_aggregated.sort_values(by='classifier', inplace=True)\n",
    "full_data_aggregated.sort_values(by='classifier', inplace=True)\n",
    "\n",
    "# Extract the sorted list of classifiers\n",
    "classifiers = reduced_data_aggregated['classifier'].values\n",
    "positions = np.arange(len(classifiers))\n",
    "bar_width = 0.35\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot for reduced channel data with error bars\n",
    "plt.bar(positions - bar_width/2, reduced_data_aggregated['mean_accuracy'], bar_width, \n",
    "        yerr=reduced_data_aggregated['std_accuracy'], capsize=5, label='Reduced', alpha=0.6)\n",
    "\n",
    "# Plot for full channel data with error bars\n",
    "plt.bar(positions + bar_width/2, full_data_aggregated['mean_accuracy'], bar_width, \n",
    "        yerr=full_data_aggregated['std_accuracy'], capsize=5, label='Full', alpha=0.6)\n",
    "\n",
    "# Customizing the plot\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Classifier Accuracy for Reduced and Full Channel Analysis (With Error Bars)')\n",
    "plt.xticks(positions, classifiers, rotation=45)\n",
    "plt.legend(title='Channel Type')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.677723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.693343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.692464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.690748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.709098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier  mean_accuracy\n",
       "0                 KNN       0.677723\n",
       "1                 LDA       0.693343\n",
       "2  LogisticRegression       0.692464\n",
       "3        RandomForest       0.690748\n",
       "4                 SVM       0.709098"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_data_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>mean_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.943317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.934926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.939114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.946484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.948708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier  mean_accuracy\n",
       "0                 KNN       0.943317\n",
       "1                 LDA       0.934926\n",
       "2  LogisticRegression       0.939114\n",
       "3        RandomForest       0.946484\n",
       "4                 SVM       0.948708"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data_aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by classifier and calculate the mean and standard deviation\n",
    "classifier_summary = classification_data.groupby('classifier').agg(\n",
    "    mean_accuracy=('mean_accuracy', 'mean'),\n",
    "    std_accuracy=('std_accuracy', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(classifier_summary['classifier'], classifier_summary['mean_accuracy'], \n",
    "        yerr=classifier_summary['std_accuracy'], capsize=5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Classification Accuracy by Classifier (with Error Bars)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file_path = 'classification_results_3FBCSP_perband_summary.csv'\n",
    "new_classification_data = pd.read_csv(new_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "classifiers = new_classification_data['classifier'].unique()\n",
    "bar_width = 0.15\n",
    "positions = np.arange(len(new_classification_data['band'].unique()))\n",
    "\n",
    "# Reorder the bands to be 'theta', 'alpha', 'beta'\n",
    "new_classification_data['band'] = pd.Categorical(new_classification_data['band'], categories=['theta', 'alpha', 'beta'], ordered=True)\n",
    "\n",
    "# Sort the data by the new band order\n",
    "new_classification_data = new_classification_data.sort_values('band')\n",
    "\n",
    "\n",
    "# Replot with the reordered bands\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "# Loop through classifiers and plot each one separately with reordered bands\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    classifier_data = new_classification_data[new_classification_data['classifier'] == classifier]\n",
    "    offset_positions = [pos + i * bar_width for pos in positions]\n",
    "    \n",
    "    plt.bar(offset_positions, classifier_data['avg_accuracy'], bar_width, \n",
    "            yerr=classifier_data['std_accuracy'], capsize=5, label=classifier)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Frequency Band')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Classification Accuracy by Classifier and Frequency Band (with Error Bars)')\n",
    "plt.xticks([pos + bar_width * (len(classifiers) / 2 - 0.5) for pos in positions], ['theta', 'alpha', 'beta'])  # Center the ticks\n",
    "plt.legend(title='Classifier')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "logo_detailed_file_path = 'Powerband_classification_results_perband.csv'\n",
    "logo_detailed_data = pd.read_csv(logo_detailed_file_path)\n",
    "\n",
    "# Set the classifiers and other plotting parameters\n",
    "classifiers = logo_detailed_data['classifier'].unique()\n",
    "bar_width = 0.15\n",
    "positions = np.arange(len(logo_detailed_data['band'].unique()))\n",
    "\n",
    "# Reorder the bands to be 'theta', 'alpha', 'beta'\n",
    "logo_detailed_data['band'] = pd.Categorical(logo_detailed_data['band'], categories=['theta', 'alpha', 'beta'], ordered=True)\n",
    "\n",
    "# Sort the data by the new band order\n",
    "logo_detailed_data = logo_detailed_data.sort_values('band')\n",
    "\n",
    "# Replot with the reordered bands\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Loop through classifiers and plot each one separately with reordered bands\n",
    "for i, classifier in enumerate(classifiers):\n",
    "    classifier_data = logo_detailed_data[logo_detailed_data['classifier'] == classifier]\n",
    "    \n",
    "    # Aggregate mean and std accuracy for each band\n",
    "    aggregated_data = classifier_data.groupby('band').agg(\n",
    "        mean_accuracy=('mean_accuracy', 'mean'),\n",
    "        std_accuracy=('std_accuracy', 'mean')  # Taking mean of stds for simplicity\n",
    "    ).loc[['theta', 'alpha', 'beta']]\n",
    "    \n",
    "    offset_positions = [pos + i * bar_width for pos in positions]\n",
    "    \n",
    "    plt.bar(offset_positions, aggregated_data['mean_accuracy'], bar_width, \n",
    "            yerr=aggregated_data['std_accuracy'], capsize=5, label=classifier)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Frequency Band')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Classification Accuracy by Classifier and Frequency Band (with Error Bars)')\n",
    "plt.xticks([pos + bar_width * (len(classifiers) / 2 - 0.5) for pos in positions], ['theta', 'alpha', 'beta'])  # Center the ticks\n",
    "plt.legend(title='Classifier')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: LogisticRegression\n",
      "Friedman test statistic=39.0000, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0043, corrected p-value=0.0130, effect size=-0.5657\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "\n",
      "Classifier: SVM\n",
      "Friedman test statistic=36.0833, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.8996, corrected p-value=1.0000, effect size=-0.0292\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "\n",
      "Classifier: LDA\n",
      "Friedman test statistic=41.3333, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0010, corrected p-value=0.0029, effect size=-0.6415\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "\n",
      "Classifier: KNN\n",
      "              Anova\n",
      "==================================\n",
      "     F Value Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "band 55.9545 2.0000 46.0000 0.0000\n",
      "==================================\n",
      "\n",
      "Comparison ('theta', 'alpha'): p-value=0.7755, corrected p-value=1.0000, effect size=-0.0589\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-1.4536\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-1.7672\n",
      "\n",
      "Classifier: RandomForest\n",
      "Friedman test statistic=36.0833, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.4908, corrected p-value=1.0000, effect size=-0.1458\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, friedmanchisquare, wilcoxon\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Powerband_classification_results_perband.csv')\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = data['classifier'].unique()\n",
    "\n",
    "# Initialize a results dictionary\n",
    "results = {}\n",
    "\n",
    "# For each classifier\n",
    "for clf in classifiers:\n",
    "    clf_data = data[data['classifier'] == clf]\n",
    "    bands = clf_data['band'].unique()\n",
    "    accuracies = {}\n",
    "    \n",
    "    # Collect accuracies for each band\n",
    "    for band in bands:\n",
    "        band_data = clf_data[clf_data['band'] == band]\n",
    "        accuracies[band] = band_data['mean_accuracy'].values\n",
    "    \n",
    "    # Check for normality\n",
    "    normality_pvalues = {}\n",
    "    for band in bands:\n",
    "        stat, p = shapiro(accuracies[band])\n",
    "        normality_pvalues[band] = p\n",
    "    \n",
    "    # Decide whether data is normally distributed\n",
    "    normal = all(p > 0.05 for p in normality_pvalues.values())\n",
    "    \n",
    "    # Initialize lists to store pairwise comparison results\n",
    "    p_values = []\n",
    "    comparisons = []\n",
    "    effect_sizes = []\n",
    "    \n",
    "    # Pairwise combinations of bands\n",
    "    band_pairs = list(combinations(bands, 2))\n",
    "    \n",
    "    if normal:\n",
    "        # Perform repeated measures ANOVA\n",
    "        anova_data = pd.DataFrame({\n",
    "            'participant': np.tile(range(1, len(accuracies[bands[0]]) + 1), len(bands)),\n",
    "            'band': np.repeat(bands, len(accuracies[bands[0]])),\n",
    "            'accuracy': np.concatenate([accuracies[band] for band in bands])\n",
    "        })\n",
    "        anova = AnovaRM(anova_data, 'accuracy', 'participant', within=['band'])\n",
    "        anova_results = anova.fit()\n",
    "        print(f'\\nClassifier: {clf}')\n",
    "        print(anova_results)\n",
    "        \n",
    "        # Perform pairwise t-tests with Bonferroni correction\n",
    "        for (band1, band2) in band_pairs:\n",
    "            stat, p = ttest_rel(accuracies[band1], accuracies[band2])\n",
    "            p_values.append(p)\n",
    "            comparisons.append((band1, band2))\n",
    "            # Calculate Cohen's d for effect size\n",
    "            diff = accuracies[band1] - accuracies[band2]\n",
    "            d = diff.mean() / diff.std(ddof=1)\n",
    "            effect_sizes.append(d)\n",
    "    else:\n",
    "        # Perform Friedman test\n",
    "        data_matrix = np.array([accuracies[band] for band in bands]).T\n",
    "        stat, p = friedmanchisquare(*[data_matrix[:, i] for i in range(data_matrix.shape[1])])\n",
    "        print(f'\\nClassifier: {clf}')\n",
    "        print(f'Friedman test statistic={stat:.4f}, p-value={p:.4f}')\n",
    "        \n",
    "        # Perform pairwise Wilcoxon tests with Bonferroni correction\n",
    "        for (band1, band2) in band_pairs:\n",
    "            stat, p = wilcoxon(accuracies[band1], accuracies[band2])\n",
    "            p_values.append(p)\n",
    "            comparisons.append((band1, band2))\n",
    "            # Calculate effect size r\n",
    "            z = (stat - (len(accuracies[band1]) * (len(accuracies[band1]) + 1) / 4)) / np.sqrt(len(accuracies[band1]) * (len(accuracies[band1]) + 1) * (2 * len(accuracies[band1]) + 1) / 24)\n",
    "            r = z / np.sqrt(len(accuracies[band1]))\n",
    "            effect_sizes.append(r)\n",
    "    \n",
    "    # Apply Bonferroni correction\n",
    "    corrected_p = multipletests(p_values, method='bonferroni')[1]\n",
    "    \n",
    "    # Store results\n",
    "    results[clf] = {\n",
    "        'comparisons': comparisons,\n",
    "        'p_values': p_values,\n",
    "        'corrected_p': corrected_p,\n",
    "        'effect_sizes': effect_sizes\n",
    "    }\n",
    "    \n",
    "    # Print pairwise comparison results\n",
    "    for i in range(len(comparisons)):\n",
    "        comp = comparisons[i]\n",
    "        print(f'Comparison {comp}: p-value={p_values[i]:.4f}, corrected p-value={corrected_p[i]:.4f}, effect size={effect_sizes[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier: LogisticRegression\n",
      "Friedman test statistic=22.7500, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0011, corrected p-value=0.0033, effect size=-0.6357\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0001, effect size=-0.7582\n",
      "Comparison ('alpha', 'beta'): p-value=0.0004, corrected p-value=0.0011, effect size=-0.6824\n",
      "\n",
      "Classifier: SVM\n",
      "Friedman test statistic=33.5833, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0005, corrected p-value=0.0015, effect size=-0.6707\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8573\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8048\n",
      "\n",
      "Classifier: LDA\n",
      "              Anova\n",
      "==================================\n",
      "     F Value Num DF  Den DF Pr > F\n",
      "----------------------------------\n",
      "band 19.1178 2.0000 46.0000 0.0000\n",
      "==================================\n",
      "\n",
      "Comparison ('theta', 'alpha'): p-value=0.0010, corrected p-value=0.0031, effect size=-0.7670\n",
      "Comparison ('theta', 'beta'): p-value=0.0001, corrected p-value=0.0002, effect size=-0.9838\n",
      "Comparison ('alpha', 'beta'): p-value=0.0010, corrected p-value=0.0029, effect size=-0.7723\n",
      "\n",
      "Classifier: KNN\n",
      "Friedman test statistic=32.2500, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0002, corrected p-value=0.0006, effect size=-0.7057\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8573\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8632\n",
      "\n",
      "Classifier: RandomForest\n",
      "Friedman test statistic=35.5833, p-value=0.0000\n",
      "Comparison ('theta', 'alpha'): p-value=0.0001, corrected p-value=0.0002, effect size=-0.7465\n",
      "Comparison ('theta', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8748\n",
      "Comparison ('alpha', 'beta'): p-value=0.0000, corrected p-value=0.0000, effect size=-0.8340\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, friedmanchisquare, wilcoxon\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from itertools import combinations\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('classification_results_3FBCSP__perband_detailed.csv')\n",
    "\n",
    "# List of classifiers\n",
    "classifiers = data['classifier'].unique()\n",
    "\n",
    "# Initialize a results dictionary\n",
    "results = {}\n",
    "\n",
    "# For each classifier\n",
    "for clf in classifiers:\n",
    "    clf_data = data[data['classifier'] == clf]\n",
    "    bands = clf_data['band'].unique()\n",
    "    accuracies = {}\n",
    "    \n",
    "    # Collect accuracies for each band\n",
    "    for band in bands:\n",
    "        band_data = clf_data[clf_data['band'] == band]\n",
    "        accuracies[band] = band_data['mean_accuracy'].values\n",
    "    \n",
    "    # Check for normality\n",
    "    normality_pvalues = {}\n",
    "    for band in bands:\n",
    "        stat, p = shapiro(accuracies[band])\n",
    "        normality_pvalues[band] = p\n",
    "    \n",
    "    # Decide whether data is normally distributed\n",
    "    normal = all(p > 0.05 for p in normality_pvalues.values())\n",
    "    \n",
    "    # Initialize lists to store pairwise comparison results\n",
    "    p_values = []\n",
    "    comparisons = []\n",
    "    effect_sizes = []\n",
    "    \n",
    "    # Pairwise combinations of bands\n",
    "    band_pairs = list(combinations(bands, 2))\n",
    "    \n",
    "    if normal:\n",
    "        # Perform repeated measures ANOVA\n",
    "        anova_data = pd.DataFrame({\n",
    "            'participant': np.tile(range(1, len(accuracies[bands[0]]) + 1), len(bands)),\n",
    "            'band': np.repeat(bands, len(accuracies[bands[0]])),\n",
    "            'accuracy': np.concatenate([accuracies[band] for band in bands])\n",
    "        })\n",
    "        anova = AnovaRM(anova_data, 'accuracy', 'participant', within=['band'])\n",
    "        anova_results = anova.fit()\n",
    "        print(f'\\nClassifier: {clf}')\n",
    "        print(anova_results)\n",
    "        \n",
    "        # Perform pairwise t-tests with Bonferroni correction\n",
    "        for (band1, band2) in band_pairs:\n",
    "            stat, p = ttest_rel(accuracies[band1], accuracies[band2])\n",
    "            p_values.append(p)\n",
    "            comparisons.append((band1, band2))\n",
    "            # Calculate Cohen's d for effect size\n",
    "            diff = accuracies[band1] - accuracies[band2]\n",
    "            d = diff.mean() / diff.std(ddof=1)\n",
    "            effect_sizes.append(d)\n",
    "    else:\n",
    "        # Perform Friedman test\n",
    "        data_matrix = np.array([accuracies[band] for band in bands]).T\n",
    "        stat, p = friedmanchisquare(*[data_matrix[:, i] for i in range(data_matrix.shape[1])])\n",
    "        print(f'\\nClassifier: {clf}')\n",
    "        print(f'Friedman test statistic={stat:.4f}, p-value={p:.4f}')\n",
    "        \n",
    "        # Perform pairwise Wilcoxon tests with Bonferroni correction\n",
    "        for (band1, band2) in band_pairs:\n",
    "            stat, p = wilcoxon(accuracies[band1], accuracies[band2])\n",
    "            p_values.append(p)\n",
    "            comparisons.append((band1, band2))\n",
    "            # Calculate effect size r\n",
    "            z = (stat - (len(accuracies[band1]) * (len(accuracies[band1]) + 1) / 4)) / np.sqrt(len(accuracies[band1]) * (len(accuracies[band1]) + 1) * (2 * len(accuracies[band1]) + 1) / 24)\n",
    "            r = z / np.sqrt(len(accuracies[band1]))\n",
    "            effect_sizes.append(r)\n",
    "    \n",
    "    # Apply Bonferroni correction\n",
    "    corrected_p = multipletests(p_values, method='bonferroni')[1]\n",
    "    \n",
    "    # Store results\n",
    "    results[clf] = {\n",
    "        'comparisons': comparisons,\n",
    "        'p_values': p_values,\n",
    "        'corrected_p': corrected_p,\n",
    "        'effect_sizes': effect_sizes\n",
    "    }\n",
    "    \n",
    "    # Print pairwise comparison results\n",
    "    for i in range(len(comparisons)):\n",
    "        comp = comparisons[i]\n",
    "        print(f'Comparison {comp}: p-value={p_values[i]:.4f}, corrected p-value={corrected_p[i]:.4f}, effect size={effect_sizes[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>participant_left_out</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.537998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.399763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.504478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.519789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>6</td>\n",
       "      <td>0.495364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier  participant_left_out     score\n",
       "0  LogisticRegression                     1  0.537998\n",
       "1  LogisticRegression                     2  0.399763\n",
       "2  LogisticRegression                     3  0.504478\n",
       "3  LogisticRegression                     4  0.519789\n",
       "4  LogisticRegression                     6  0.495364"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logo_detailed_file_path = 'classification_results_3FBCSP_logo_detailed.csv'\n",
    "logo_detailed_data = pd.read_csv(logo_detailed_file_path)\n",
    "logo_detailed_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erangad\\Desktop\\Research\\reading_task\\src\\Classification_plots.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy_stats_per_classifier \u001b[39m=\u001b[39m logo_detailed_data\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39magg([\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreset_index()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Create a bar plot with error bars representing the standard deviation\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m,\u001b[39m6\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mbar(accuracy_stats_per_classifier[\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m], accuracy_stats_per_classifier[\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         yerr\u001b[39m=\u001b[39maccuracy_stats_per_classifier[\u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m], capsize\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Customize the plot\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the standard deviation of accuracy for each classifier\n",
    "accuracy_stats_per_classifier = logo_detailed_data.groupby('classifier')['score'].agg(['mean', 'std']).reset_index()\n",
    "\n",
    "# Create a bar plot with error bars representing the standard deviation\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(accuracy_stats_per_classifier['classifier'], accuracy_stats_per_classifier['mean'], \n",
    "        yerr=accuracy_stats_per_classifier['std'], capsize=5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Average Classification Accuracy by Classifier (with Error Bars)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   participant          classifier  mean_accuracy  std_accuracy\n",
       " 0            1  LogisticRegression       0.702001      0.027968\n",
       " 1            1                 LDA       0.692377      0.027743\n",
       " 2            1                 SVM       0.668258      0.044061\n",
       " 3            1        RandomForest       0.624834      0.028296\n",
       " 4            1                 KNN       0.569361      0.025416,\n",
       "    participant          classifier  mean_accuracy  std_accuracy\n",
       " 0            1  LogisticRegression       0.815400      0.039922\n",
       " 1            1                 SVM       0.846776      0.021968\n",
       " 2            1                 LDA       0.799723      0.040773\n",
       " 3            1                 KNN       0.821475      0.018075\n",
       " 4            1        RandomForest       0.844359      0.019117,\n",
       "    participant          classifier  mean_accuracy  std_accuracy\n",
       " 0            1  LogisticRegression       0.819051      0.036782\n",
       " 1            1                 SVM       0.848003      0.025710\n",
       " 2            1                 LDA       0.811807      0.043235\n",
       " 3            1                 KNN       0.823870      0.031820\n",
       " 4            1        RandomForest       0.860051      0.028473)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load all three CSV files to check their contents\n",
    "file1_path = 'classification_results.csv'\n",
    "file2_path = 'classification_results_2.csv'\n",
    "file3_path = 'classification_results_3_fbcsp.csv'\n",
    "\n",
    "# Load the data\n",
    "classification1_data = pd.read_csv(file1_path)\n",
    "classification2_data = pd.read_csv(file2_path)\n",
    "classification3_data = pd.read_csv(file3_path)\n",
    "\n",
    "# Display the first few rows of each to understand their structure\n",
    "classification1_data.head(), classification2_data.head(), classification3_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erangad\\Desktop\\Research\\reading_task\\src\\Classification_plots.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m combined_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([classification1_data, classification2_data, classification3_data])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Create a boxplot to show classifier performance grouped by feature extraction method\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sns\u001b[39m.\u001b[39mboxplot(x\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfeature_extraction\u001b[39m\u001b[39m'\u001b[39m, y\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_accuracy\u001b[39m\u001b[39m'\u001b[39m, hue\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m'\u001b[39m, data\u001b[39m=\u001b[39mcombined_data, notch \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/Classification_plots.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Customize the plot\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Add a column to each dataset to indicate the feature extraction method\n",
    "classification1_data['feature_extraction'] = 'Powerband features'\n",
    "classification2_data['feature_extraction'] = 'CSP filters'\n",
    "classification3_data['feature_extraction'] = 'Filterbank CSP filters'\n",
    "\n",
    "# Combine all datasets into one\n",
    "combined_data = pd.concat([classification1_data, classification2_data, classification3_data])\n",
    "\n",
    "# Create a boxplot to show classifier performance grouped by feature extraction method\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='feature_extraction', y='mean_accuracy', hue='classifier', data=combined_data, notch = True)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Feature Extraction Method')\n",
    "plt.ylabel('Classification Accuracy')\n",
    "plt.title('Classifier Performance by Feature Extraction Method')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 len: 120\n",
      "2 len: 120\n",
      "3 len: 120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(39.0), np.float64(0.0008462667465209961)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(4.0),\n",
       "    np.float64(8.344650268554688e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(19.0),\n",
       "    np.float64(3.6597251892089844e-05))}),\n",
       " 'LDA': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(15.0), np.float64(1.633167266845703e-05)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(10.0),\n",
       "    np.float64(5.125999450683594e-06))}),\n",
       " 'SVM': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(6.0), np.float64(1.6689300537109375e-06)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(30.0),\n",
       "    np.float64(0.00023925304412841797))}),\n",
       " 'RandomForest': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(4.0), np.float64(8.344650268554688e-07)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(2.0),\n",
       "    np.float64(3.5762786865234375e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(23.0),\n",
       "    np.float64(7.62939453125e-05))}),\n",
       " 'KNN': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(1.0), np.float64(2.384185791015625e-07)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(42.0),\n",
       "    np.float64(0.0012379884719848633))})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract accuracy values for each classifier grouped by participants for statistical analysis\n",
    "# Include all participant accuracies for each feature extraction method\n",
    "from scipy.stats import shapiro, f_oneway, wilcoxon\n",
    "\n",
    "# Prepare data for each classifier\n",
    "statistical_results = {}\n",
    "classifiers = classification1_data['classifier'].unique()\n",
    "\n",
    "valid_pids = [el for el in range(1, 32) if el not in [5, 13, 14, 16, 17, 20, 31]]\n",
    "\n",
    "# Filter each dataset to include only the valid participants\n",
    "classification1_data = classification1_data[classification1_data['participant'].isin(valid_pids)]\n",
    "classification2_data = classification2_data[classification2_data['participant'].isin(valid_pids)]\n",
    "classification3_data = classification3_data[classification3_data['participant'].isin(valid_pids)]\n",
    "\n",
    "print(\"1 len: \" + str(len(classification1_data)))\n",
    "print(\"2 len: \" + str(len(classification2_data)))\n",
    "print(\"3 len: \" + str(len(classification3_data)))\n",
    "\n",
    "\n",
    "# Perform normality test for Logistic Regression across all feature extraction methods\n",
    "classification1_data_temp = classification1_data[classification1_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "classification2_data_temp = classification2_data[classification2_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "classification3_data_temp = classification3_data[classification3_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "\n",
    "# Combine all accuracies for Logistic Regression\n",
    "logreg_all_accuracies = pd.concat([classification1_data_temp, classification2_data_temp, classification3_data_temp])\n",
    "\n",
    "# Normality test using Shapiro-Wilk for Logistic Regression\n",
    "normality_test_stat, normality_p_value = shapiro(logreg_all_accuracies)\n",
    "\n",
    "# Check if the data is normally distributed\n",
    "if normality_p_value > 0.05:\n",
    "    # Data is normally distributed; use one-way ANOVA (F-test) for comparisons\n",
    "    for classifier in classifiers:\n",
    "        # Get participant accuracies for the current classifier across feature extraction methods\n",
    "        acc_powerband = classification1_data[classification1_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_csp = classification2_data[classification2_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_fbcsp = classification3_data[classification3_data['classifier'] == classifier]['mean_accuracy']\n",
    "\n",
    "        # Perform one-way ANOVA test\n",
    "        f_stat, p_value = f_oneway(acc_powerband, acc_csp, acc_fbcsp)\n",
    "        statistical_results[classifier] = ('ANOVA', f_stat, p_value)\n",
    "else:\n",
    "    # Data is not normally distributed; use Wilcoxon rank-sum test for pairwise comparisons\n",
    "    for classifier in classifiers:\n",
    "        pairwise_results = {}\n",
    "        \n",
    "        # Get participant accuracies for each pair of feature extraction methods\n",
    "        acc_powerband = classification1_data[classification1_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_csp = classification2_data[classification2_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_fbcsp = classification3_data[classification3_data['classifier'] == classifier]['mean_accuracy']\n",
    "\n",
    "        # Powerband vs CSP\n",
    "        wilcoxon_stat_1, p_value_1 = wilcoxon(acc_powerband, acc_csp)\n",
    "        pairwise_results['Powerband vs CSP'] = (wilcoxon_stat_1, p_value_1)\n",
    "        \n",
    "        # Powerband vs Filterbank CSP\n",
    "        wilcoxon_stat_2, p_value_2 = wilcoxon(acc_powerband, acc_fbcsp)\n",
    "        pairwise_results['Powerband vs Filterbank CSP'] = (wilcoxon_stat_2, p_value_2)\n",
    "        \n",
    "        # CSP vs Filterbank CSP\n",
    "        wilcoxon_stat_3, p_value_3 = wilcoxon(acc_csp, acc_fbcsp)\n",
    "        pairwise_results['CSP vs Filterbank CSP'] = (wilcoxon_stat_3, p_value_3)\n",
    "\n",
    "        statistical_results[classifier] = ('Wilcoxon', pairwise_results)\n",
    "\n",
    "# Display the results\n",
    "statistical_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Classifier': 'LogisticRegression',\n",
       "  'Powerband Mean Accuracy': np.float64(0.8522539273333334),\n",
       "  'CSP Mean Accuracy': np.float64(0.913709085875),\n",
       "  'Filterbank CSP Mean Accuracy': np.float64(0.9391142743237282)},\n",
       " {'Classifier': 'LDA',\n",
       "  'Powerband Mean Accuracy': np.float64(0.8253539350833333),\n",
       "  'CSP Mean Accuracy': np.float64(0.9063081445416667),\n",
       "  'Filterbank CSP Mean Accuracy': np.float64(0.9349256651099327)},\n",
       " {'Classifier': 'SVM',\n",
       "  'Powerband Mean Accuracy': np.float64(0.8377550545416668),\n",
       "  'CSP Mean Accuracy': np.float64(0.9343010077083335),\n",
       "  'Filterbank CSP Mean Accuracy': np.float64(0.9487076020602453)},\n",
       " {'Classifier': 'RandomForest',\n",
       "  'Powerband Mean Accuracy': np.float64(0.8117575702500001),\n",
       "  'CSP Mean Accuracy': np.float64(0.9319298104166668),\n",
       "  'Filterbank CSP Mean Accuracy': np.float64(0.9464839137053271)},\n",
       " {'Classifier': 'KNN',\n",
       "  'Powerband Mean Accuracy': np.float64(0.7543674976250001),\n",
       "  'CSP Mean Accuracy': np.float64(0.9313536300833333),\n",
       "  'Filterbank CSP Mean Accuracy': np.float64(0.9433173231402097)}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a dictionary to store the mean accuracies\n",
    "mean_accuracies = []\n",
    "\n",
    "# Iterate through each classifier to calculate the mean accuracy for each feature extraction method\n",
    "for classifier in classifiers:\n",
    "    # Calculate mean accuracies for the current classifier\n",
    "    mean_acc_powerband = classification1_data[classification1_data['classifier'] == classifier]['mean_accuracy'].mean()\n",
    "    mean_acc_csp = classification2_data[classification2_data['classifier'] == classifier]['mean_accuracy'].mean()\n",
    "    mean_acc_fbcsp = classification3_data[classification3_data['classifier'] == classifier]['mean_accuracy'].mean()\n",
    "    \n",
    "    # Store results in a list of dictionaries\n",
    "    mean_accuracies.append({\n",
    "        'Classifier': classifier,\n",
    "        'Powerband Mean Accuracy': mean_acc_powerband,\n",
    "        'CSP Mean Accuracy': mean_acc_csp,\n",
    "        'Filterbank CSP Mean Accuracy': mean_acc_fbcsp\n",
    "    })\n",
    "\n",
    "# Convert to a DataFrame for easier viewing\n",
    "mean_accuracies_df = pd.DataFrame(mean_accuracies)\n",
    "mean_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Original p-value</th>\n",
       "      <th>Bonferroni-corrected p-value</th>\n",
       "      <th>Benjamini-Hochberg-corrected p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>8.462667e-04</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>9.067144e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.788139e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>3.659725e-05</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>4.990534e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>1.633167e-05</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>2.449751e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.940697e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>5.125999e-06</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>8.543332e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>1.668930e-06</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>3.129244e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.940697e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>2.392530e-04</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>2.760612e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>1.788139e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.072884e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>7.629395e-05</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>9.536743e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.940697e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>8.940697e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>1.237988e-03</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>1.237988e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier                   Comparison  Original p-value  \\\n",
       "0   LogisticRegression             Powerband vs CSP      8.462667e-04   \n",
       "1   LogisticRegression  Powerband vs Filterbank CSP      8.344650e-07   \n",
       "2   LogisticRegression        CSP vs Filterbank CSP      3.659725e-05   \n",
       "3                  LDA             Powerband vs CSP      1.633167e-05   \n",
       "4                  LDA  Powerband vs Filterbank CSP      2.384186e-07   \n",
       "5                  LDA        CSP vs Filterbank CSP      5.125999e-06   \n",
       "6                  SVM             Powerband vs CSP      1.668930e-06   \n",
       "7                  SVM  Powerband vs Filterbank CSP      2.384186e-07   \n",
       "8                  SVM        CSP vs Filterbank CSP      2.392530e-04   \n",
       "9         RandomForest             Powerband vs CSP      8.344650e-07   \n",
       "10        RandomForest  Powerband vs Filterbank CSP      3.576279e-07   \n",
       "11        RandomForest        CSP vs Filterbank CSP      7.629395e-05   \n",
       "12                 KNN             Powerband vs CSP      2.384186e-07   \n",
       "13                 KNN  Powerband vs Filterbank CSP      2.384186e-07   \n",
       "14                 KNN        CSP vs Filterbank CSP      1.237988e-03   \n",
       "\n",
       "    Bonferroni-corrected p-value  Benjamini-Hochberg-corrected p-value  \n",
       "0                       0.012694                          9.067144e-04  \n",
       "1                       0.000013                          1.788139e-06  \n",
       "2                       0.000549                          4.990534e-05  \n",
       "3                       0.000245                          2.449751e-05  \n",
       "4                       0.000004                          8.940697e-07  \n",
       "5                       0.000077                          8.543332e-06  \n",
       "6                       0.000025                          3.129244e-06  \n",
       "7                       0.000004                          8.940697e-07  \n",
       "8                       0.003589                          2.760612e-04  \n",
       "9                       0.000013                          1.788139e-06  \n",
       "10                      0.000005                          1.072884e-06  \n",
       "11                      0.001144                          9.536743e-05  \n",
       "12                      0.000004                          8.940697e-07  \n",
       "13                      0.000004                          8.940697e-07  \n",
       "14                      0.018570                          1.237988e-03  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Extract all p-values from the statistical results for correction\n",
    "p_values = []\n",
    "comparisons = []\n",
    "\n",
    "for classifier, (test_type, results) in statistical_results.items():\n",
    "    if isinstance(results, dict):  # Ensure there are pairwise comparisons\n",
    "        for comparison, (stat, p_value) in results.items():\n",
    "            p_values.append(p_value)\n",
    "            comparisons.append((classifier, comparison))\n",
    "\n",
    "# Apply Bonferroni and Benjamini-Hochberg corrections\n",
    "bonferroni_corrected = multipletests(p_values, method='bonferroni')\n",
    "bh_corrected = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "# Collect and format the results\n",
    "correction_results = []\n",
    "\n",
    "for i, (classifier, comparison) in enumerate(comparisons):\n",
    "    original_p = p_values[i]\n",
    "    bonf_corrected_p = bonferroni_corrected[1][i]\n",
    "    bh_corrected_p = bh_corrected[1][i]\n",
    "    correction_results.append({\n",
    "        'Classifier': classifier,\n",
    "        'Comparison': comparison,\n",
    "        'Original p-value': original_p,\n",
    "        'Bonferroni-corrected p-value': bonf_corrected_p,\n",
    "        'Benjamini-Hochberg-corrected p-value': bh_corrected_p\n",
    "    })\n",
    "\n",
    "# Display the corrected p-values\n",
    "correction_results_df = pd.DataFrame(correction_results)\n",
    "\n",
    "correction_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Wilcoxon Stat</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Rank-Biserial Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.462667e-04</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.659725e-05</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.633167e-05</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.125999e-06</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.668930e-06</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.392530e-04</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.629395e-05</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.237988e-03</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier                   Comparison  Wilcoxon Stat  \\\n",
       "0   LogisticRegression             Powerband vs CSP           39.0   \n",
       "1   LogisticRegression  Powerband vs Filterbank CSP            4.0   \n",
       "2   LogisticRegression        CSP vs Filterbank CSP           19.0   \n",
       "3                  LDA             Powerband vs CSP           15.0   \n",
       "4                  LDA  Powerband vs Filterbank CSP            1.0   \n",
       "5                  LDA        CSP vs Filterbank CSP           10.0   \n",
       "6                  SVM             Powerband vs CSP            6.0   \n",
       "7                  SVM  Powerband vs Filterbank CSP            1.0   \n",
       "8                  SVM        CSP vs Filterbank CSP           30.0   \n",
       "9         RandomForest             Powerband vs CSP            4.0   \n",
       "10        RandomForest  Powerband vs Filterbank CSP            2.0   \n",
       "11        RandomForest        CSP vs Filterbank CSP           23.0   \n",
       "12                 KNN             Powerband vs CSP            1.0   \n",
       "13                 KNN  Powerband vs Filterbank CSP            1.0   \n",
       "14                 KNN        CSP vs Filterbank CSP           42.0   \n",
       "\n",
       "         p-value  Rank-Biserial Correlation  \n",
       "0   8.462667e-04                   0.740000  \n",
       "1   8.344650e-07                   0.973333  \n",
       "2   3.659725e-05                   0.873333  \n",
       "3   1.633167e-05                   0.900000  \n",
       "4   2.384186e-07                   0.993333  \n",
       "5   5.125999e-06                   0.933333  \n",
       "6   1.668930e-06                   0.960000  \n",
       "7   2.384186e-07                   0.993333  \n",
       "8   2.392530e-04                   0.800000  \n",
       "9   8.344650e-07                   0.973333  \n",
       "10  3.576279e-07                   0.986667  \n",
       "11  7.629395e-05                   0.846667  \n",
       "12  2.384186e-07                   0.993333  \n",
       "13  2.384186e-07                   0.993333  \n",
       "14  1.237988e-03                   0.720000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate rank-biserial correlation for Wilcoxon signed-rank test\n",
    "def rank_biserial(w_stat, n):\n",
    "    return 1 - (2 * w_stat / (n * (n + 1) / 2))\n",
    "\n",
    "# Calculate effect sizes (rank-biserial correlation) for each pairwise Wilcoxon test\n",
    "effect_sizes = []\n",
    "\n",
    "for classifier, (test_type, results) in statistical_results.items():\n",
    "    if isinstance(results, dict):  # Ensure there are pairwise comparisons\n",
    "        for comparison, (w_stat, p_value) in results.items():\n",
    "            # Number of observations (valid PIDs)\n",
    "            n = len(valid_pids)\n",
    "\n",
    "            # Calculate rank-biserial correlation\n",
    "            rb_correlation = rank_biserial(w_stat, n)\n",
    "\n",
    "            # Store the results\n",
    "            effect_sizes.append({\n",
    "                'Classifier': classifier,\n",
    "                'Comparison': comparison,\n",
    "                'Wilcoxon Stat': w_stat,\n",
    "                'p-value': p_value,\n",
    "                'Rank-Biserial Correlation': rb_correlation\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for the effect sizes\n",
    "effect_sizes_df = pd.DataFrame(effect_sizes)\n",
    "\n",
    "effect_sizes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11120\\1845782889.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification1_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\erangad\\AppData\\Local\\anaconda3\\envs\\eeg\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   6295\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6296\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6297\u001b[0m         ):\n\u001b[0;32m   6298\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6299\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "print(classification1_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LogisticRegression': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(39.0), np.float64(0.0008462667465209961)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(4.0),\n",
       "    np.float64(8.344650268554688e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(19.0),\n",
       "    np.float64(3.6597251892089844e-05))}),\n",
       " 'LDA': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(15.0), np.float64(1.633167266845703e-05)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(10.0),\n",
       "    np.float64(5.125999450683594e-06))}),\n",
       " 'SVM': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(6.0), np.float64(1.6689300537109375e-06)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(30.0),\n",
       "    np.float64(0.00023925304412841797))}),\n",
       " 'RandomForest': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(4.0), np.float64(8.344650268554688e-07)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(2.0),\n",
       "    np.float64(3.5762786865234375e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(23.0),\n",
       "    np.float64(7.62939453125e-05))}),\n",
       " 'KNN': ('Wilcoxon',\n",
       "  {'Powerband vs CSP': (np.float64(1.0), np.float64(2.384185791015625e-07)),\n",
       "   'Powerband vs Filterbank CSP': (np.float64(1.0),\n",
       "    np.float64(2.384185791015625e-07)),\n",
       "   'CSP vs Filterbank CSP': (np.float64(42.0),\n",
       "    np.float64(0.0012379884719848633))})}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform normality test for Logistic Regression across all feature extraction methods\n",
    "logreg_accuracies_powerband = classification1_data[classification1_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "logreg_accuracies_csp = classification2_data[classification2_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "logreg_accuracies_fbcsp = classification3_data[classification3_data['classifier'] == 'LogisticRegression']['mean_accuracy']\n",
    "\n",
    "# Combine all accuracies for Logistic Regression\n",
    "logreg_all_accuracies = pd.concat([logreg_accuracies_powerband, logreg_accuracies_csp, logreg_accuracies_fbcsp])\n",
    "\n",
    "# Normality test using Shapiro-Wilk for Logistic Regression\n",
    "normality_test_stat, normality_p_value = shapiro(logreg_all_accuracies)\n",
    "\n",
    "# Prepare data for each classifier\n",
    "statistical_results = {}\n",
    "classifiers = classification1_data['classifier'].unique()\n",
    "\n",
    "# Check if the data is normally distributed\n",
    "if normality_p_value > 0.05:\n",
    "    # Data is normally distributed; use one-way ANOVA (F-test) for comparisons\n",
    "    for classifier in classifiers:\n",
    "        # Get participant accuracies for the current classifier across feature extraction methods\n",
    "        acc_powerband = classification1_data[classification1_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_csp = classification2_data[classification2_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_fbcsp = classification3_data[classification3_data['classifier'] == classifier]['mean_accuracy']\n",
    "\n",
    "        # Perform one-way ANOVA test\n",
    "        f_stat, p_value = f_oneway(acc_powerband, acc_csp, acc_fbcsp)\n",
    "        statistical_results[classifier] = ('ANOVA', f_stat, p_value)\n",
    "else:\n",
    "    # Data is not normally distributed; use Wilcoxon rank-sum test for pairwise comparisons\n",
    "    for classifier in classifiers:\n",
    "        pairwise_results = {}\n",
    "\n",
    "        # Get participant accuracies for each pair of feature extraction methods\n",
    "        acc_powerband = classification1_data[classification1_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_csp = classification2_data[classification2_data['classifier'] == classifier]['mean_accuracy']\n",
    "        acc_fbcsp = classification3_data[classification3_data['classifier'] == classifier]['mean_accuracy']\n",
    "\n",
    "        # Powerband vs CSP\n",
    "        wilcoxon_stat_1, p_value_1 = wilcoxon(acc_powerband, acc_csp)\n",
    "        pairwise_results['Powerband vs CSP'] = (wilcoxon_stat_1, p_value_1)\n",
    "\n",
    "        # Powerband vs Filterbank CSP\n",
    "        wilcoxon_stat_2, p_value_2 = wilcoxon(acc_powerband, acc_fbcsp)\n",
    "        pairwise_results['Powerband vs Filterbank CSP'] = (wilcoxon_stat_2, p_value_2)\n",
    "\n",
    "        # CSP vs Filterbank CSP\n",
    "        wilcoxon_stat_3, p_value_3 = wilcoxon(acc_csp, acc_fbcsp)\n",
    "        pairwise_results['CSP vs Filterbank CSP'] = (wilcoxon_stat_3, p_value_3)\n",
    "\n",
    "        statistical_results[classifier] = ('Wilcoxon', pairwise_results)\n",
    "\n",
    "# Display the results\n",
    "statistical_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Bonferroni-corrected p-value</th>\n",
       "      <th>Rank-Biserial Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>0.012694</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>0.000549</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>0.018570</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier                   Comparison  \\\n",
       "0   LogisticRegression             Powerband vs CSP   \n",
       "1   LogisticRegression  Powerband vs Filterbank CSP   \n",
       "2   LogisticRegression        CSP vs Filterbank CSP   \n",
       "3                  LDA             Powerband vs CSP   \n",
       "4                  LDA  Powerband vs Filterbank CSP   \n",
       "5                  LDA        CSP vs Filterbank CSP   \n",
       "6                  SVM             Powerband vs CSP   \n",
       "7                  SVM  Powerband vs Filterbank CSP   \n",
       "8                  SVM        CSP vs Filterbank CSP   \n",
       "9         RandomForest             Powerband vs CSP   \n",
       "10        RandomForest  Powerband vs Filterbank CSP   \n",
       "11        RandomForest        CSP vs Filterbank CSP   \n",
       "12                 KNN             Powerband vs CSP   \n",
       "13                 KNN  Powerband vs Filterbank CSP   \n",
       "14                 KNN        CSP vs Filterbank CSP   \n",
       "\n",
       "    Bonferroni-corrected p-value  Rank-Biserial Correlation  \n",
       "0                       0.012694                   0.740000  \n",
       "1                       0.000013                   0.973333  \n",
       "2                       0.000549                   0.873333  \n",
       "3                       0.000245                   0.900000  \n",
       "4                       0.000004                   0.993333  \n",
       "5                       0.000077                   0.933333  \n",
       "6                       0.000025                   0.960000  \n",
       "7                       0.000004                   0.993333  \n",
       "8                       0.003589                   0.800000  \n",
       "9                       0.000013                   0.973333  \n",
       "10                      0.000005                   0.986667  \n",
       "11                      0.001144                   0.846667  \n",
       "12                      0.000004                   0.993333  \n",
       "13                      0.000004                   0.993333  \n",
       "14                      0.018570                   0.720000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Extract all p-values from the statistical results for correction\n",
    "p_values = []\n",
    "comparisons = []\n",
    "rb_correlations = []\n",
    "\n",
    "def rank_biserial(w_stat, n):\n",
    "    return 1 - (2 * w_stat / (n * (n + 1) / 2))\n",
    "\n",
    "for classifier, (test_type, results) in statistical_results.items():\n",
    "    if isinstance(results, dict):  # Ensure there are pairwise comparisons\n",
    "        for comparison, (stat, p_value) in results.items():\n",
    "            n = len(valid_pids)\n",
    "\n",
    "            # Calculate rank-biserial correlation\n",
    "            rb_correlation = rank_biserial(stat, n)\n",
    "            rb_correlations.append(rb_correlation)\n",
    "\n",
    "            p_values.append(p_value)\n",
    "            comparisons.append((classifier, comparison))\n",
    "\n",
    "# Apply Bonferroni and Benjamini-Hochberg corrections\n",
    "bonferroni_corrected = multipletests(p_values, method='bonferroni')\n",
    "bh_corrected = multipletests(p_values, method='fdr_bh')\n",
    "\n",
    "# Collect and format the results\n",
    "correction_results = []\n",
    "\n",
    "for i, (classifier, comparison) in enumerate(comparisons):\n",
    "    original_p = p_values[i]\n",
    "    bonf_corrected_p = bonferroni_corrected[1][i]\n",
    "    bh_corrected_p = bh_corrected[1][i]\n",
    "    correction_results.append({\n",
    "        'Classifier': classifier,\n",
    "        'Comparison': comparison,\n",
    "        # 'Original p-value': original_p,\n",
    "        'Bonferroni-corrected p-value': bonf_corrected_p,\n",
    "        # 'Benjamini-Hochberg-corrected p-value': bh_corrected_p,\n",
    "         'Rank-Biserial Correlation': rb_correlations[i]\n",
    "    })\n",
    "\n",
    "# Display the corrected p-values\n",
    "correction_results_df = pd.DataFrame(correction_results)\n",
    "\n",
    "correction_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Comparison</th>\n",
       "      <th>Wilcoxon Stat</th>\n",
       "      <th>p-value</th>\n",
       "      <th>Rank-Biserial Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.462667e-04</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.659725e-05</td>\n",
       "      <td>0.873333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.633167e-05</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LDA</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LDA</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.125999e-06</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.668930e-06</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.392530e-04</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.344650e-07</td>\n",
       "      <td>0.973333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.576279e-07</td>\n",
       "      <td>0.986667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.629395e-05</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Powerband vs Filterbank CSP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>0.993333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>CSP vs Filterbank CSP</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.237988e-03</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Classifier                   Comparison  Wilcoxon Stat  \\\n",
       "0   LogisticRegression             Powerband vs CSP           39.0   \n",
       "1   LogisticRegression  Powerband vs Filterbank CSP            4.0   \n",
       "2   LogisticRegression        CSP vs Filterbank CSP           19.0   \n",
       "3                  LDA             Powerband vs CSP           15.0   \n",
       "4                  LDA  Powerband vs Filterbank CSP            1.0   \n",
       "5                  LDA        CSP vs Filterbank CSP           10.0   \n",
       "6                  SVM             Powerband vs CSP            6.0   \n",
       "7                  SVM  Powerband vs Filterbank CSP            1.0   \n",
       "8                  SVM        CSP vs Filterbank CSP           30.0   \n",
       "9         RandomForest             Powerband vs CSP            4.0   \n",
       "10        RandomForest  Powerband vs Filterbank CSP            2.0   \n",
       "11        RandomForest        CSP vs Filterbank CSP           23.0   \n",
       "12                 KNN             Powerband vs CSP            1.0   \n",
       "13                 KNN  Powerband vs Filterbank CSP            1.0   \n",
       "14                 KNN        CSP vs Filterbank CSP           42.0   \n",
       "\n",
       "         p-value  Rank-Biserial Correlation  \n",
       "0   8.462667e-04                   0.740000  \n",
       "1   8.344650e-07                   0.973333  \n",
       "2   3.659725e-05                   0.873333  \n",
       "3   1.633167e-05                   0.900000  \n",
       "4   2.384186e-07                   0.993333  \n",
       "5   5.125999e-06                   0.933333  \n",
       "6   1.668930e-06                   0.960000  \n",
       "7   2.384186e-07                   0.993333  \n",
       "8   2.392530e-04                   0.800000  \n",
       "9   8.344650e-07                   0.973333  \n",
       "10  3.576279e-07                   0.986667  \n",
       "11  7.629395e-05                   0.846667  \n",
       "12  2.384186e-07                   0.993333  \n",
       "13  2.384186e-07                   0.993333  \n",
       "14  1.237988e-03                   0.720000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate rank-biserial correlation for Wilcoxon signed-rank test\n",
    "def rank_biserial(w_stat, n):\n",
    "    return 1 - (2 * w_stat / (n * (n + 1) / 2))\n",
    "\n",
    "# Calculate effect sizes (rank-biserial correlation) for each pairwise Wilcoxon test\n",
    "effect_sizes = []\n",
    "\n",
    "for classifier, (test_type, results) in statistical_results.items():\n",
    "    if isinstance(results, dict):  # Ensure there are pairwise comparisons\n",
    "        for comparison, (w_stat, p_value) in results.items():\n",
    "            # Number of observations (valid PIDs)\n",
    "            n = len(valid_pids)\n",
    "\n",
    "            # Calculate rank-biserial correlation\n",
    "            rb_correlation = rank_biserial(w_stat, n)\n",
    "\n",
    "            # Store the results\n",
    "            effect_sizes.append({\n",
    "                'Classifier': classifier,\n",
    "                'Comparison': comparison,\n",
    "                'Wilcoxon Stat': w_stat,\n",
    "                'p-value': p_value,\n",
    "                'Rank-Biserial Correlation': rb_correlation\n",
    "            })\n",
    "\n",
    "# Create a DataFrame for the effect sizes\n",
    "effect_sizes_df = pd.DataFrame(effect_sizes)\n",
    "\n",
    "\n",
    "effect_sizes_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Analysis for Powerband Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0077\n",
      "Classifier: LDA, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0810\n",
      "Classifier: RandomForest, p-value: 0.0372\n",
      "Classifier: KNN, p-value: 0.8508\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Kruskal-Wallis Test.\n",
      "Kruskal-Wallis H-statistic: 25.4897, p-value: 0.0000\n",
      "Effect Size (Epsilon Squared): 0.1869\n",
      "\n",
      "Post-hoc Analysis (Dunn's Test with Bonferroni correction):\n",
      "                         KNN       LDA  LogisticRegression  RandomForest  \\\n",
      "KNN                 1.000000  0.022273            0.000023      0.374399   \n",
      "LDA                 0.022273  1.000000            0.961289      1.000000   \n",
      "LogisticRegression  0.000023  0.961289            1.000000      0.082636   \n",
      "RandomForest        0.374399  1.000000            0.082636      1.000000   \n",
      "SVM                 0.002895  1.000000            1.000000      1.000000   \n",
      "\n",
      "                         SVM  \n",
      "KNN                 0.002895  \n",
      "LDA                 1.000000  \n",
      "LogisticRegression  1.000000  \n",
      "RandomForest        1.000000  \n",
      "SVM                 1.000000  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0040\n",
      "Classifier: SVM, p-value: 0.0138\n",
      "Classifier: LDA, p-value: 0.0115\n",
      "Classifier: KNN, p-value: 0.0241\n",
      "Classifier: RandomForest, p-value: 0.0070\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Kruskal-Wallis Test.\n",
      "Kruskal-Wallis H-statistic: 4.1617, p-value: 0.3846\n",
      "Effect Size (Epsilon Squared): 0.0014\n",
      "\n",
      "Post-hoc Analysis (Dunn's Test with Bonferroni correction):\n",
      "                    KNN       LDA  LogisticRegression  RandomForest       SVM\n",
      "KNN                 1.0  1.000000                 1.0           1.0  1.000000\n",
      "LDA                 1.0  1.000000                 1.0           1.0  0.888915\n",
      "LogisticRegression  1.0  1.000000                 1.0           1.0  1.000000\n",
      "RandomForest        1.0  1.000000                 1.0           1.0  1.000000\n",
      "SVM                 1.0  0.888915                 1.0           1.0  1.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for Filter Bank CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0026\n",
      "Classifier: LDA, p-value: 0.0018\n",
      "Classifier: KNN, p-value: 0.0011\n",
      "Classifier: RandomForest, p-value: 0.0018\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Kruskal-Wallis Test.\n",
      "Kruskal-Wallis H-statistic: 0.6665, p-value: 0.9554\n",
      "Effect Size (Epsilon Squared): -0.0290\n",
      "\n",
      "Post-hoc Analysis (Dunn's Test with Bonferroni correction):\n",
      "                    KNN  LDA  LogisticRegression  RandomForest  SVM\n",
      "KNN                 1.0  1.0                 1.0           1.0  1.0\n",
      "LDA                 1.0  1.0                 1.0           1.0  1.0\n",
      "LogisticRegression  1.0  1.0                 1.0           1.0  1.0\n",
      "RandomForest        1.0  1.0                 1.0           1.0  1.0\n",
      "SVM                 1.0  1.0                 1.0           1.0  1.0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, f_oneway, kruskal\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "classification1_data = pd.read_csv('classification_results.csv')\n",
    "classification2_data = pd.read_csv('classification_results_2.csv')\n",
    "classification3_data = pd.read_csv('classification_results_3_fbcsp.csv')\n",
    "\n",
    "def perform_statistical_analysis(data, feature_extraction_name):\n",
    "    print(f\"\\nStatistical Analysis for {feature_extraction_name} Feature Extraction Method\")\n",
    "    classifiers = data['classifier'].unique()\n",
    "    accuracies = [data[data['classifier'] == clf]['mean_accuracy'] for clf in classifiers]\n",
    "    all_accuracies = data['mean_accuracy']\n",
    "    \n",
    "    # Normality test for each classifier\n",
    "    normality_results = {}\n",
    "    print(\"\\nNormality Test Results (Shapiro-Wilk):\")\n",
    "    for clf in classifiers:\n",
    "        clf_data = data[data['classifier'] == clf]['mean_accuracy']\n",
    "        stat, p = shapiro(clf_data)\n",
    "        normality_results[clf] = p\n",
    "        print(f\"Classifier: {clf}, p-value: {p:.4f}\")\n",
    "    \n",
    "    # Check if all classifiers have normally distributed data\n",
    "    if all(p > 0.05 for p in normality_results.values()):\n",
    "        print(\"\\nData is normally distributed across all classifiers. Proceeding with One-way ANOVA.\")\n",
    "        # One-way ANOVA\n",
    "        f_stat, p_value = f_oneway(*accuracies)\n",
    "        print(f\"ANOVA F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Effect Size (Eta Squared)\n",
    "        grand_mean = np.mean(all_accuracies)\n",
    "        ss_total = sum((all_accuracies - grand_mean) ** 2)\n",
    "        ss_between = sum(len(acc) * (np.mean(acc) - grand_mean) ** 2 for acc in accuracies)\n",
    "        eta_squared = ss_between / ss_total\n",
    "        print(f\"Effect Size (Eta Squared): {eta_squared:.4f}\")\n",
    "        \n",
    "        # Post-hoc Tukey HSD test\n",
    "        tukey = pairwise_tukeyhsd(endog=data['mean_accuracy'], groups=data['classifier'], alpha=0.05)\n",
    "        print(\"\\nPost-hoc Analysis (Tukey HSD):\")\n",
    "        print(tukey.summary())\n",
    "    else:\n",
    "        print(\"\\nData is not normally distributed across all classifiers. Proceeding with Kruskal-Wallis Test.\")\n",
    "        # Kruskal-Wallis Test\n",
    "        h_stat, p_value = kruskal(*accuracies)\n",
    "        print(f\"Kruskal-Wallis H-statistic: {h_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Effect Size (Epsilon Squared)\n",
    "        n = len(data)\n",
    "        k = len(classifiers)\n",
    "        epsilon_squared = (h_stat - k + 1) / (n - k)\n",
    "        print(f\"Effect Size (Epsilon Squared): {epsilon_squared:.4f}\")\n",
    "        \n",
    "        # Post-hoc Dunn's Test with Bonferroni correction\n",
    "        dunn_results = sp.posthoc_dunn(data, val_col='mean_accuracy', group_col='classifier', p_adjust='bonferroni')\n",
    "        print(\"\\nPost-hoc Analysis (Dunn's Test with Bonferroni correction):\")\n",
    "        print(dunn_results)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Perform statistical analysis on each feature extraction method\n",
    "perform_statistical_analysis(classification1_data, 'Powerband')\n",
    "perform_statistical_analysis(classification2_data, 'CSP')\n",
    "perform_statistical_analysis(classification3_data, 'Filter Bank CSP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Analysis for Powerband Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0077\n",
      "Classifier: LDA, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0810\n",
      "Classifier: RandomForest, p-value: 0.0372\n",
      "Classifier: KNN, p-value: 0.8508\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 59.8163, p-value: 0.0000\n",
      "Effect Size (Kendall's W): 0.6231\n",
      "\n",
      "Post-hoc Analysis (Nemenyi test):\n",
      "                         KNN       LDA  LogisticRegression       SVM  \\\n",
      "KNN                 1.000000  0.006425            0.001000  0.016871   \n",
      "LDA                 0.006425  1.000000            0.900000  0.900000   \n",
      "LogisticRegression  0.001000  0.900000            1.000000  0.737028   \n",
      "SVM                 0.016871  0.900000            0.737028  1.000000   \n",
      "RandomForest        0.728394  0.182923            0.017703  0.316241   \n",
      "\n",
      "                    RandomForest  \n",
      "KNN                     0.728394  \n",
      "LDA                     0.182923  \n",
      "LogisticRegression      0.017703  \n",
      "SVM                     0.316241  \n",
      "RandomForest            1.000000  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0040\n",
      "Classifier: SVM, p-value: 0.0138\n",
      "Classifier: LDA, p-value: 0.0115\n",
      "Classifier: KNN, p-value: 0.0241\n",
      "Classifier: RandomForest, p-value: 0.0070\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 45.1789, p-value: 0.0000\n",
      "Effect Size (Kendall's W): 0.4706\n",
      "\n",
      "Post-hoc Analysis (Nemenyi test):\n",
      "                    KNN       LDA  LogisticRegression  RandomForest       SVM\n",
      "KNN                 1.0  0.900000            0.900000           0.9  0.900000\n",
      "LDA                 0.9  1.000000            0.900000           0.9  0.731848\n",
      "LogisticRegression  0.9  0.900000            1.000000           0.9  0.887271\n",
      "RandomForest        0.9  0.900000            0.900000           1.0  0.900000\n",
      "SVM                 0.9  0.731848            0.887271           0.9  1.000000\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for Filter Bank CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0026\n",
      "Classifier: LDA, p-value: 0.0018\n",
      "Classifier: KNN, p-value: 0.0011\n",
      "Classifier: RandomForest, p-value: 0.0018\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 20.0597, p-value: 0.0005\n",
      "Effect Size (Kendall's W): 0.2090\n",
      "\n",
      "Post-hoc Analysis (Nemenyi test):\n",
      "                    KNN  LDA  LogisticRegression  RandomForest  SVM\n",
      "KNN                 1.0  0.9                 0.9           0.9  0.9\n",
      "LDA                 0.9  1.0                 0.9           0.9  0.9\n",
      "LogisticRegression  0.9  0.9                 1.0           0.9  0.9\n",
      "RandomForest        0.9  0.9                 0.9           1.0  0.9\n",
      "SVM                 0.9  0.9                 0.9           0.9  1.0\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, f_oneway, friedmanchisquare\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import scikit_posthocs as sp\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data\n",
    "classification1_data = pd.read_csv('classification_results.csv')\n",
    "classification2_data = pd.read_csv('classification_results_2.csv')\n",
    "classification3_data = pd.read_csv('classification_results_3_fbcsp.csv')\n",
    "\n",
    "def perform_statistical_analysis(data, feature_extraction_name):\n",
    "    print(f\"\\nStatistical Analysis for {feature_extraction_name} Feature Extraction Method\")\n",
    "    classifiers = data['classifier'].unique()\n",
    "    all_accuracies = data['mean_accuracy']\n",
    "    \n",
    "    # Ensure 'subject' column exists for repeated measures\n",
    "    if 'subject' not in data.columns:\n",
    "        # Assign a subject ID to each observation\n",
    "        # Assumes that each classifier has the same number of observations\n",
    "        n_subjects = int(len(data) / len(classifiers))\n",
    "        data['subject'] = np.tile(range(1, n_subjects + 1), len(classifiers))\n",
    "    \n",
    "    # Normality test for each classifier\n",
    "    normality_results = {}\n",
    "    print(\"\\nNormality Test Results (Shapiro-Wilk):\")\n",
    "    for clf in classifiers:\n",
    "        clf_data = data[data['classifier'] == clf]['mean_accuracy']\n",
    "        stat, p = shapiro(clf_data)\n",
    "        normality_results[clf] = p\n",
    "        print(f\"Classifier: {clf}, p-value: {p:.4f}\")\n",
    "    \n",
    "    # Prepare data for statistical tests\n",
    "    accuracies = [data[data['classifier'] == clf]['mean_accuracy'].values for clf in classifiers]\n",
    "    \n",
    "    # Check if all classifiers have normally distributed data\n",
    "    if all(p > 0.05 for p in normality_results.values()):\n",
    "        print(\"\\nData is normally distributed across all classifiers. Proceeding with One-way ANOVA.\")\n",
    "        # One-way ANOVA\n",
    "        f_stat, p_value = f_oneway(*accuracies)\n",
    "        print(f\"ANOVA F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Effect Size (Eta Squared)\n",
    "        grand_mean = np.mean(all_accuracies)\n",
    "        ss_total = sum((all_accuracies - grand_mean) ** 2)\n",
    "        ss_between = sum(len(acc) * (np.mean(acc) - grand_mean) ** 2 for acc in accuracies)\n",
    "        eta_squared = ss_between / ss_total\n",
    "        print(f\"Effect Size (Eta Squared): {eta_squared:.4f}\")\n",
    "        \n",
    "        # Post-hoc Tukey HSD test\n",
    "        tukey = pairwise_tukeyhsd(endog=data['mean_accuracy'], groups=data['classifier'], alpha=0.05)\n",
    "        print(\"\\nPost-hoc Analysis (Tukey HSD):\")\n",
    "        print(tukey.summary())\n",
    "    else:\n",
    "        print(\"\\nData is not normally distributed across all classifiers. Proceeding with Friedman Test.\")\n",
    "        # Friedman Test\n",
    "        chi_square_stat, p_value = friedmanchisquare(*accuracies)\n",
    "        print(f\"Friedman Chi-Square statistic: {chi_square_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "        # Effect Size (Kendall's W)\n",
    "        n = len(data['subject'].unique())  # Number of subjects\n",
    "        k = len(classifiers)  # Number of conditions\n",
    "        kendalls_w = chi_square_stat / (n * (k - 1))\n",
    "        print(f\"Effect Size (Kendall's W): {kendalls_w:.4f}\")\n",
    "        \n",
    "        # Post-hoc Nemenyi test\n",
    "        nemenyi_results = sp.posthoc_nemenyi_friedman(data.groupby(['subject', 'classifier'])['mean_accuracy'].mean().reset_index(), y_col='mean_accuracy', block_col='subject', group_col='classifier', melted= True)\n",
    "        print(\"\\nPost-hoc Analysis (Nemenyi test):\")\n",
    "        print(nemenyi_results)\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Perform statistical analysis on each feature extraction method\n",
    "perform_statistical_analysis(classification1_data, 'Powerband')\n",
    "perform_statistical_analysis(classification2_data, 'CSP')\n",
    "perform_statistical_analysis(classification3_data, 'Filter Bank CSP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Analysis for Powerband Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0077\n",
      "Classifier: LDA, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0810\n",
      "Classifier: RandomForest, p-value: 0.0372\n",
      "Classifier: KNN, p-value: 0.8508\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 59.8163, p-value: 0.0000\n",
      "Effect Size (Kendall's W): 0.6231\n",
      "\n",
      "Post-hoc Analysis (Conover test with Bonferroni correction):\n",
      "                    LogisticRegression           LDA           SVM  \\\n",
      "LogisticRegression        1.000000e+00  2.890579e-06  1.242594e-01   \n",
      "LDA                       2.890579e-06  1.000000e+00  3.609528e-02   \n",
      "SVM                       1.242594e-01  3.609528e-02  1.000000e+00   \n",
      "RandomForest              2.252788e-08  1.000000e+00  9.575673e-04   \n",
      "KNN                       1.612421e-18  4.317433e-07  3.498565e-13   \n",
      "\n",
      "                    RandomForest           KNN  \n",
      "LogisticRegression  2.252788e-08  1.612421e-18  \n",
      "LDA                 1.000000e+00  4.317433e-07  \n",
      "SVM                 9.575673e-04  3.498565e-13  \n",
      "RandomForest        1.000000e+00  4.412730e-05  \n",
      "KNN                 4.412730e-05  1.000000e+00  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0040\n",
      "Classifier: SVM, p-value: 0.0138\n",
      "Classifier: LDA, p-value: 0.0115\n",
      "Classifier: KNN, p-value: 0.0241\n",
      "Classifier: RandomForest, p-value: 0.0070\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 45.1789, p-value: 0.0000\n",
      "Effect Size (Kendall's W): 0.4706\n",
      "\n",
      "Post-hoc Analysis (Conover test with Bonferroni correction):\n",
      "                    LogisticRegression           SVM           LDA  \\\n",
      "LogisticRegression        1.000000e+00  9.158267e-07  2.112937e-01   \n",
      "SVM                       9.158267e-07  1.000000e+00  1.763526e-11   \n",
      "LDA                       2.112937e-01  1.763526e-11  1.000000e+00   \n",
      "KNN                       2.924289e-03  4.450024e-01  2.346631e-07   \n",
      "RandomForest              9.357359e-02  2.213412e-02  2.724199e-05   \n",
      "\n",
      "                             KNN  RandomForest  \n",
      "LogisticRegression  2.924289e-03      0.093574  \n",
      "SVM                 4.450024e-01      0.022134  \n",
      "LDA                 2.346631e-07      0.000027  \n",
      "KNN                 1.000000e+00      1.000000  \n",
      "RandomForest        1.000000e+00      1.000000  \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Statistical Analysis for Filter Bank CSP Feature Extraction Method\n",
      "\n",
      "Normality Test Results (Shapiro-Wilk):\n",
      "Classifier: LogisticRegression, p-value: 0.0002\n",
      "Classifier: SVM, p-value: 0.0026\n",
      "Classifier: LDA, p-value: 0.0018\n",
      "Classifier: KNN, p-value: 0.0011\n",
      "Classifier: RandomForest, p-value: 0.0018\n",
      "\n",
      "Data is not normally distributed across all classifiers. Proceeding with Friedman Test.\n",
      "Friedman Chi-Square statistic: 20.0597, p-value: 0.0005\n",
      "Effect Size (Kendall's W): 0.2090\n",
      "\n",
      "Post-hoc Analysis (Conover test with Bonferroni correction):\n",
      "                    LogisticRegression       SVM       LDA       KNN  \\\n",
      "LogisticRegression            1.000000  0.004214  1.000000  1.000000   \n",
      "SVM                           0.004214  1.000000  0.000100  0.054556   \n",
      "LDA                           1.000000  0.000100  1.000000  0.705374   \n",
      "KNN                           1.000000  0.054556  0.705374  1.000000   \n",
      "RandomForest                  1.000000  0.029941  1.000000  1.000000   \n",
      "\n",
      "                    RandomForest  \n",
      "LogisticRegression      1.000000  \n",
      "SVM                     0.029941  \n",
      "LDA                     1.000000  \n",
      "KNN                     1.000000  \n",
      "RandomForest            1.000000  \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from scipy.stats import shapiro, f_oneway, friedmanchisquare\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "# import scikit_posthocs as sp\n",
    "# import warnings\n",
    "\n",
    "# # Suppress warnings for cleaner output\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Load the data\n",
    "# classification1_data = pd.read_csv('classification_results.csv')\n",
    "# classification2_data = pd.read_csv('classification_results_2.csv')\n",
    "# classification3_data = pd.read_csv('classification_results_3_fbcsp.csv')\n",
    "\n",
    "# def perform_statistical_analysis(data, feature_extraction_name):\n",
    "#     print(f\"\\nStatistical Analysis for {feature_extraction_name} Feature Extraction Method\")\n",
    "#     classifiers = data['classifier'].unique()\n",
    "#     all_accuracies = data['mean_accuracy']\n",
    "    \n",
    "#     # Ensure 'participant' column exists and is correctly assigned\n",
    "#     if 'participant' not in data.columns:\n",
    "#         n_classifiers = len(classifiers)\n",
    "#         n_participants = int(len(data) / n_classifiers)\n",
    "        \n",
    "#         # Sort data by 'classifier' for consistent assignment\n",
    "#         data = data.sort_values(by='classifier')\n",
    "#         data['participant'] = np.repeat(range(1, n_participants + 1), n_classifiers)\n",
    "        \n",
    "#         # Re-sort data to original order if necessary\n",
    "#         data = data.sort_index()\n",
    "    \n",
    "#     # Convert data types\n",
    "#     data['mean_accuracy'] = pd.to_numeric(data['mean_accuracy'], errors='coerce')\n",
    "#     data['participant'] = data['participant'].astype(str)\n",
    "#     data['classifier'] = data['classifier'].astype(str)\n",
    "#     data = data.dropna(subset=['mean_accuracy'])\n",
    "    \n",
    "#     # Normality test for each classifier\n",
    "#     normality_results = {}\n",
    "#     print(\"\\nNormality Test Results (Shapiro-Wilk):\")\n",
    "#     for clf in classifiers:\n",
    "#         clf_data = data[data['classifier'] == clf]['mean_accuracy']\n",
    "#         stat, p = shapiro(clf_data)\n",
    "#         normality_results[clf] = p\n",
    "#         print(f\"Classifier: {clf}, p-value: {p:.4f}\")\n",
    "    \n",
    "#     # Prepare data for statistical tests\n",
    "#     accuracies = [data[data['classifier'] == clf]['mean_accuracy'].values for clf in classifiers]\n",
    "    \n",
    "#     # Check if all classifiers have normally distributed data\n",
    "#     if all(p > 0.05 for p in normality_results.values()):\n",
    "#         print(\"\\nData is normally distributed across all classifiers. Proceeding with One-way ANOVA.\")\n",
    "#         # One-way ANOVA\n",
    "#         f_stat, p_value = f_oneway(*accuracies)\n",
    "#         print(f\"ANOVA F-statistic: {f_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "#         # Effect Size (Eta Squared)\n",
    "#         grand_mean = np.mean(all_accuracies)\n",
    "#         ss_total = sum((all_accuracies - grand_mean) ** 2)\n",
    "#         ss_between = sum(len(acc) * (np.mean(acc) - grand_mean) ** 2 for acc in accuracies)\n",
    "#         eta_squared = ss_between / ss_total\n",
    "#         print(f\"Effect Size (Eta Squared): {eta_squared:.4f}\")\n",
    "        \n",
    "#         # Post-hoc Tukey HSD test\n",
    "#         tukey = pairwise_tukeyhsd(endog=data['mean_accuracy'], groups=data['classifier'], alpha=0.05)\n",
    "#         print(\"\\nPost-hoc Analysis (Tukey HSD):\")\n",
    "#         print(tukey.summary())\n",
    "#     else:\n",
    "#         print(\"\\nData is not normally distributed across all classifiers. Proceeding with Friedman Test.\")\n",
    "#         # Friedman Test\n",
    "#         chi_square_stat, p_value = friedmanchisquare(*accuracies)\n",
    "#         print(f\"Friedman Chi-Square statistic: {chi_square_stat:.4f}, p-value: {p_value:.4f}\")\n",
    "        \n",
    "#         # Effect Size (Kendall's W)\n",
    "#         n = len(data['participant'].unique())  # Number of participants\n",
    "#         k = len(classifiers)  # Number of conditions\n",
    "#         kendalls_w = chi_square_stat / (n * (k - 1))\n",
    "#         print(f\"Effect Size (Kendall's W): {kendalls_w:.4f}\")\n",
    "        \n",
    "#         # Post-hoc Conover test with melted=True\n",
    "#         conover_results = sp.posthoc_conover_friedman(\n",
    "#             data,\n",
    "#             y_col='mean_accuracy',\n",
    "#             block_col='participant',\n",
    "#             group_col='classifier',\n",
    "#             melted=True,\n",
    "#             p_adjust='bonferroni'\n",
    "#         )\n",
    "#         print(\"\\nPost-hoc Analysis (Conover test with Bonferroni correction):\")\n",
    "#         print(conover_results)\n",
    "    \n",
    "#     print(\"-\" * 80)\n",
    "\n",
    "# # Perform statistical analysis on each feature extraction method\n",
    "# perform_statistical_analysis(classification1_data, 'Powerband')\n",
    "# perform_statistical_analysis(classification2_data, 'CSP')\n",
    "# perform_statistical_analysis(classification3_data, 'Filter Bank CSP')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean Accuracy and Standard Deviation for Powerband Feature Extraction Method\n",
      "{'Mean Accuracy': np.float64(0.8162975969666667), 'Standard Deviation': np.float64(0.07222931694531354)}\n",
      "\n",
      "Mean Accuracy and Standard Deviation for CSP Feature Extraction Method\n",
      "{'Mean Accuracy': np.float64(0.9235203357249999), 'Standard Deviation': np.float64(0.05345525378441496)}\n",
      "\n",
      "Mean Accuracy and Standard Deviation for Filter Bank CSP Feature Extraction Method\n",
      "{'Mean Accuracy': np.float64(0.9425097556678886), 'Standard Deviation': np.float64(0.04507038871342122)}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "classification1_data = pd.read_csv('classification_results.csv')\n",
    "classification2_data = pd.read_csv('classification_results_2.csv')\n",
    "classification3_data = pd.read_csv('classification_results_3_fbcsp.csv')\n",
    "\n",
    "def calculate_mean_sd(data, feature_extraction_name):\n",
    "    print(f\"\\nMean Accuracy and Standard Deviation for {feature_extraction_name} Feature Extraction Method\")\n",
    "\n",
    "    clf_data = data['mean_accuracy']\n",
    "    mean_acc = clf_data.mean()\n",
    "    std_acc = clf_data.std()\n",
    "    stats = {'Mean Accuracy': mean_acc, 'Standard Deviation': std_acc}\n",
    "\n",
    "    print(stats)\n",
    "\n",
    "# Calculate mean and SD for each feature extraction method\n",
    "calculate_mean_sd(classification1_data, 'Powerband')\n",
    "calculate_mean_sd(classification2_data, 'CSP')\n",
    "calculate_mean_sd(classification3_data, 'Filter Bank CSP')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
