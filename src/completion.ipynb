{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt6.QtCore\n",
    "import os\n",
    "os.environ[\"QT_API\"] = \"pyqt6\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use qt backend for matplotlab to use interactive mne plots\n",
    "%matplotlib qt\n",
    "\n",
    "import mne \n",
    "import analysis.processing\n",
    "import pandas as pd\n",
    "import csv \n",
    "import os\n",
    "from config import Config\n",
    "configObj = Config()\n",
    "from mne_connectivity import spectral_connectivity_time\n",
    "import numpy as np\n",
    "configss = configObj.getConfigSnapshot()\n",
    "from tqdm import tqdm\n",
    "import tools.helpers\n",
    "from scipy import stats\n",
    "\n",
    "mne.set_log_level(verbose='WARNING', return_old_level=False, add_frames=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 8]\n",
    "plt.rcParams['figure.dpi'] = 200 # 200 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Data: 100%|██████████| 24/24 [00:00<00:00, 786.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing 16 outliers in 'completion' within each 'BlockType' group.\n",
      "\n",
      "Number of duplicate PID-BlockType combinations after aggregation: 0\n",
      "\n",
      "Shapiro-Wilk Test for BlockType 'D':\n",
      "Statistic = 0.9430, p-value = 0.1904\n",
      "\n",
      "Shapiro-Wilk Test for BlockType 'ND':\n",
      "Statistic = 0.7588, p-value = 0.0001\n",
      "\n",
      "Block Types identified for paired comparison: 'D' and 'ND'\n",
      "\n",
      "Normality for Both Blocks: Fail\n",
      "\n",
      "Data is not normally distributed. Performing Wilcoxon signed-rank test.\n",
      "\n",
      "Wilcoxon Signed-Rank Test Results:\n",
      "Statistic = 29.0, p-value = 0.0016\n",
      "Effect Size (Rank Biserial Correlation) = -0.7489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\erangad\\AppData\\Local\\Temp\\ipykernel_7612\\2273468503.py:205: FutureWarning: \n",
      "\n",
      "The `ci` parameter is deprecated. Use `errorbar=('ci', 95)` for the same effect.\n",
      "\n",
      "  sns.barplot(x='BlockType', y='completion', data=aggregated_df, ci=95, palette='viridis', capsize=0.1)\n",
      "C:\\Users\\erangad\\AppData\\Local\\Temp\\ipykernel_7612\\2273468503.py:205: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='BlockType', y='completion', data=aggregated_df, ci=95, palette='viridis', capsize=0.1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 1 does not match index length 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\erangad\\Desktop\\Research\\reading_task\\src\\completion.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=240'>241</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=241'>242</a>\u001b[0m         display_data \u001b[39m=\u001b[39m {\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=242'>243</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mMean Completion\u001b[39m\u001b[39m'\u001b[39m: mean_completion,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=243'>244</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mStd Deviation\u001b[39m\u001b[39m'\u001b[39m: std_completion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=246'>247</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mEffect Size (Partial Eta Squared)\u001b[39m\u001b[39m'\u001b[39m: [effect_size]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=247'>248</a>\u001b[0m         }\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=249'>250</a>\u001b[0m display_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(display_data)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=250'>251</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDescriptive Statistics and Effect Size:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/erangad/Desktop/Research/reading_task/src/completion.ipynb#W5sZmlsZQ%3D%3D?line=251'>252</a>\u001b[0m \u001b[39mprint\u001b[39m(display_df)\n",
      "File \u001b[1;32mc:\\Users\\erangad\\AppData\\Local\\anaconda3\\envs\\eeg\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\erangad\\AppData\\Local\\anaconda3\\envs\\eeg\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\erangad\\AppData\\Local\\anaconda3\\envs\\eeg\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\erangad\\AppData\\Local\\anaconda3\\envs\\eeg\\lib\\site-packages\\pandas\\core\\internals\\construction.py:690\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    685\u001b[0m     \u001b[39mif\u001b[39;00m lengths[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m    686\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    687\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39marray length \u001b[39m\u001b[39m{\u001b[39;00mlengths[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m does not match index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    688\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlength \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    689\u001b[0m         )\n\u001b[1;32m--> 690\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    691\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    692\u001b[0m     index \u001b[39m=\u001b[39m default_index(lengths[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 1 does not match index length 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import shapiro, wilcoxon, ttest_rel\n",
    "import pingouin as pg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Data Loading and Cleaning\n",
    "# -----------------------------\n",
    "\n",
    "# List of participant numbers excluding specified ones\n",
    "participant_numbers = [el for el in range(1, 32) if el not in [5, 13, 14, 16, 17, 20, 31]]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "for pnum in tqdm(participant_numbers, desc=\"Loading Data\"):\n",
    "    participant_data_path = f\"{pnum}.csv\"\n",
    "    path_qa = os.path.join(configss['root'], configss['data_completion'], participant_data_path)\n",
    "    \n",
    "    # Check if file exists\n",
    "    if not os.path.exists(path_qa):\n",
    "        print(f\"Warning: File {path_qa} does not exist. Skipping participant {pnum}.\")\n",
    "        continue\n",
    "    \n",
    "    # Read and append the DataFrame\n",
    "    try:\n",
    "        df_participant = pd.read_csv(path_qa)\n",
    "        df_participant['PID'] = pnum  # Ensure 'PID' column exists\n",
    "        dataframes.append(df_participant)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {path_qa}: {e}\")\n",
    "\n",
    "# Check if any data was loaded\n",
    "if not dataframes:\n",
    "    raise ValueError(\"No participant data loaded. Please check file paths and data.\")\n",
    "\n",
    "# Concatenate all DataFrames into one combined DataFrame\n",
    "combined_df = pd.concat(dataframes, axis=0).reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Outlier Replacement\n",
    "# -----------------------------\n",
    "\n",
    "def replace_outliers(df, group_col, value_col):\n",
    "    \"\"\"\n",
    "    Replace outliers in 'value_col' within each 'group_col' group with the group's median.\n",
    "    Outliers are defined as values below Q1 - 1.5*IQR or above Q3 + 1.5*IQR.\n",
    "    \"\"\"\n",
    "    df_copy = df.copy()\n",
    "    medians = df.groupby(group_col)[value_col].transform('median')\n",
    "    \n",
    "    Q1 = df[value_col].quantile(0.25)\n",
    "    Q3 = df[value_col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Replace outliers with median\n",
    "    outliers = (df[value_col] < lower_bound) | (df[value_col] > upper_bound)\n",
    "    num_outliers = outliers.sum()\n",
    "    print(f\"Replacing {num_outliers} outliers in '{value_col}' within each '{group_col}' group.\")\n",
    "    df_copy.loc[outliers, value_col] = medians[outliers]\n",
    "    \n",
    "    return df_copy\n",
    "\n",
    "# Replace outliers in the combined data\n",
    "cleaned_df = replace_outliers(combined_df, 'BlockType', 'completion')\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Data Aggregation\n",
    "# -----------------------------\n",
    "\n",
    "# Aggregate the data by computing mean 'completion' per PID and BlockType\n",
    "aggregated_df = cleaned_df.groupby(['PID', 'BlockType'])['completion'].mean().reset_index()\n",
    "\n",
    "# Verify no duplicates\n",
    "duplicate_counts = aggregated_df.duplicated(subset=['PID', 'BlockType']).sum()\n",
    "print(f\"\\nNumber of duplicate PID-BlockType combinations after aggregation: {duplicate_counts}\")\n",
    "\n",
    "if duplicate_counts > 0:\n",
    "    raise ValueError(\"Duplicates found after aggregation. Please check your data.\")\n",
    "\n",
    "# Ensure that each PID has data for all BlockTypes\n",
    "block_types = aggregated_df['BlockType'].unique()\n",
    "block_type_counts = aggregated_df.groupby('PID')['BlockType'].nunique()\n",
    "\n",
    "missing_blocktypes = block_type_counts[block_type_counts != len(block_types)].index.tolist()\n",
    "if missing_blocktypes:\n",
    "    print(f\"\\nParticipants missing some BlockTypes: {missing_blocktypes}\")\n",
    "    # Exclude these participants from the analysis\n",
    "    aggregated_df = aggregated_df[~aggregated_df['PID'].isin(missing_blocktypes)]\n",
    "    print(f\"Excluded participants missing BlockTypes. Remaining participants: {aggregated_df['PID'].nunique()}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Normality Testing on Each Block Type Separately\n",
    "# -----------------------------\n",
    "\n",
    "# Pivot the data to have one row per participant with columns for each BlockType\n",
    "pivot_df = aggregated_df.pivot(index='PID', columns='BlockType', values='completion')\n",
    "\n",
    "# Check normality for each BlockType separately\n",
    "normality_results = {}\n",
    "for block in block_types:\n",
    "    shapiro_stat, shapiro_p = shapiro(pivot_df[block])\n",
    "    normality_results[block] = {'statistic': shapiro_stat, 'p-value': shapiro_p}\n",
    "    print(f\"\\nShapiro-Wilk Test for BlockType '{block}':\")\n",
    "    print(f\"Statistic = {shapiro_stat:.4f}, p-value = {shapiro_p:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Paired Test Logic Based on Normality\n",
    "# -----------------------------\n",
    "\n",
    "if len(block_types) == 2:\n",
    "    # Exactly two BlockTypes: proceed with paired tests\n",
    "    block1, block2 = block_types\n",
    "    print(f\"\\nBlock Types identified for paired comparison: '{block1}' and '{block2}'\")\n",
    "    \n",
    "    # Calculate differences\n",
    "    pivot_df['Difference'] = pivot_df[block1] - pivot_df[block2]\n",
    "    \n",
    "    # Check if both blocks are normally distributed\n",
    "    normality = (normality_results[block1]['p-value'] > 0.05) and (normality_results[block2]['p-value'] > 0.05)\n",
    "    print(f\"\\nNormality for Both Blocks: {'Pass' if normality else 'Fail'}\")\n",
    "\n",
    "    if normality:\n",
    "        print(\"\\nData is normally distributed. Performing Paired t-test.\")\n",
    "        # Perform Paired t-test\n",
    "        t_stat, t_p_value = ttest_rel(pivot_df[block1], pivot_df[block2])\n",
    "        print(f\"\\nPaired t-test Results:\")\n",
    "        print(f\"t-statistic = {t_stat:.4f}, p-value = {t_p_value:.4f}\")\n",
    "        \n",
    "        # Calculate Cohen's d for paired samples\n",
    "        differences = pivot_df['Difference']\n",
    "        cohen_d = differences.mean() / differences.std(ddof=1)\n",
    "        print(f\"Cohen's d = {cohen_d:.4f}\")\n",
    "        \n",
    "        effect_size = cohen_d\n",
    "    else:\n",
    "        print(\"\\nData is not normally distributed. Performing Wilcoxon signed-rank test.\")\n",
    "        # Perform Wilcoxon signed-rank test\n",
    "        non_zero = pivot_df['Difference'] != 0\n",
    "        completion1 = pivot_df.loc[non_zero, block1]\n",
    "        completion2 = pivot_df.loc[non_zero, block2]\n",
    "\n",
    "        # stat, p = wilcoxon(data1, data2, alternative='two-sided')\n",
    "\n",
    "        test_res = pg.wilcoxon(completion1, completion2)\n",
    "        wilcoxon_test_stat = test_res['W-val'].values[0]\n",
    "        wilcoxon_pvalue = test_res['p-val'].values[0]\n",
    "        effect_size = test_res['RBC'].values[0]  # Rank-biserial correlation\n",
    "        effect_size_name = 'Rank-biserial correlation'\n",
    "        \n",
    "        # wilcoxon_test_stat, wilcoxon_pvalue = wilcoxon(completion1, completion2, alternative='two-sided')\n",
    "        print(f\"\\nWilcoxon Signed-Rank Test Results:\")\n",
    "        print(f\"Statistic = {wilcoxon_test_stat}, p-value = {wilcoxon_pvalue:.4f}\")\n",
    "        \n",
    "        # Calculate Effect Size (Rank Biserial Correlation) using pingouin\n",
    "        # effect_size = pg.compute_effsize(completion1, completion2, paired=True, eftype='r')\n",
    "        print(f\"Effect Size (Rank Biserial Correlation) = {effect_size:.4f}\")\n",
    "\n",
    "else:\n",
    "    # More than two BlockTypes: proceed with ANOVA or Friedman test\n",
    "    print(\"\\nMore than two BlockTypes detected.\")\n",
    "    normality = all([result['p-value'] > 0.05 for result in normality_results.values()])\n",
    "    \n",
    "    if normality:\n",
    "        print(\"\\nData is normally distributed. Performing Repeated Measures ANOVA.\")\n",
    "        aov = pg.rm_anova(\n",
    "            data=aggregated_df,\n",
    "            dv='completion',\n",
    "            within='BlockType',\n",
    "            subject='PID',\n",
    "            detailed=True\n",
    "        )\n",
    "        print(\"\\nANOVA Results:\")\n",
    "        print(aov)\n",
    "        \n",
    "        partial_eta_squared = aov.loc[aov['Source'] == 'BlockType', 'np2'].values[0]\n",
    "        print(f\"\\nPartial Eta Squared: {partial_eta_squared:.4f}\")\n",
    "        effect_size = partial_eta_squared\n",
    "    else:\n",
    "        print(\"\\nData is not normally distributed. Performing Friedman test.\")\n",
    "        friedman_data = [pivot_df[bt].dropna() for bt in block_types]\n",
    "        \n",
    "        friedman_stat, friedman_pvalue = friedmanchisquare(*friedman_data)\n",
    "        print(f\"\\nFriedman Test Results:\")\n",
    "        print(f\"Statistic = {friedman_stat:.4f}, p-value = {friedman_pvalue:.4f}\")\n",
    "        \n",
    "        N = pivot_df.shape[0]\n",
    "        k = len(block_types)\n",
    "        partial_eta_squared = friedman_stat / (N * (k - 1))\n",
    "        print(f\"Partial Eta Squared = {partial_eta_squared:.4f}\")\n",
    "        effect_size = partial_eta_squared\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Visualization\n",
    "# -----------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='BlockType', y='completion', data=aggregated_df, ci=95, palette='viridis', capsize=0.1)\n",
    "plt.title('Average Completion by Block Type')\n",
    "plt.xlabel('Block Type')\n",
    "plt.ylabel('Average Completion')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Descriptive Statistics and Effect Size Reporting\n",
    "# -----------------------------\n",
    "\n",
    "mean_completion = aggregated_df.groupby('BlockType')['completion'].mean()\n",
    "std_completion = aggregated_df.groupby('BlockType')['completion'].std()\n",
    "\n",
    "if len(block_types) == 2:\n",
    "    if normality:\n",
    "        display_data = {\n",
    "            'Mean Completion': mean_completion,\n",
    "            'Std Deviation': std_completion,\n",
    "            'Effect Size (Cohen\\'s d)': [effect_size] * len(mean_completion)\n",
    "        }\n",
    "    else:\n",
    "        display_data = {\n",
    "            'Mean Completion': mean_completion,\n",
    "            'Std Deviation': std_completion,\n",
    "            'Wilcoxon Test Statistic': [wilcoxon_test_stat],\n",
    "            'Wilcoxon P-Value': [wilcoxon_pvalue],\n",
    "            'Effect Size (r)': [effect_size]\n",
    "        }\n",
    "else:\n",
    "    if normality:\n",
    "        display_data = {\n",
    "            'Mean Completion': mean_completion,\n",
    "            'Std Deviation': std_completion,\n",
    "            'Partial Eta Squared': [effect_size] * len(mean_completion)\n",
    "        }\n",
    "    else:\n",
    "        display_data = {\n",
    "            'Mean Completion': mean_completion,\n",
    "            'Std Deviation': std_completion,\n",
    "            'Friedman Test Statistic': [friedman_stat],\n",
    "            'Friedman P-Value': [friedman_pvalue],\n",
    "            'Effect Size (Partial Eta Squared)': [effect_size]\n",
    "        }\n",
    "\n",
    "display_df = pd.DataFrame(display_data)\n",
    "print(\"\\nDescriptive Statistics and Effect Size:\")\n",
    "print(display_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Median        IQR  Quartile Deviation\n",
      "BlockType                                          \n",
      "D          91.458333  10.462240            5.231120\n",
      "ND         98.789062   6.783854            3.391927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erangad\\AppData\\Local\\Temp\\ipykernel_7612\\2104411404.py:3: FutureWarning: The provided callable <function median at 0x00000224ED756440> is currently using SeriesGroupBy.median. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"median\" instead.\n",
      "  iqr_data = df.groupby(group_col)[value_col].agg([np.median, lambda x: np.percentile(x, 75) - np.percentile(x, 25)])\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate median and IQR\n",
    "def calculate_iqr(df, group_col, value_col):\n",
    "    iqr_data = df.groupby(group_col)[value_col].agg([np.median, lambda x: np.percentile(x, 75) - np.percentile(x, 25)])\n",
    "    iqr_data.columns = ['Median', 'IQR']\n",
    "    iqr_data['Quartile Deviation'] = iqr_data['IQR'] / 2\n",
    "    return iqr_data\n",
    "\n",
    "# Calculate IQR for each condition\n",
    "iqr_df = calculate_iqr(aggregated_df, 'BlockType', 'completion')\n",
    "\n",
    "# Plot boxplot with viridis color palette\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_palette('viridis')\n",
    "sns.boxplot(x='BlockType', y='completion',data=aggregated_df)\n",
    "\n",
    "\n",
    "# Display median and IQR\n",
    "# for i, block_type in enumerate(iqr_df.index):\n",
    "#     median = iqr_df.loc[block_type, 'Median']\n",
    "#     iqr_range = iqr_df.loc[block_type, 'IQR']\n",
    "#     plt.text(i, median, f'Median: {median:.2f}\\nIQR: {iqr_range:.2f}', \n",
    "#              ha='center', va='center', color='white', fontsize=10, bbox=dict(facecolor='black', alpha=0.5))\n",
    "plt.xlabel('Block Type')\n",
    "plt.ylabel('Average Completion')\n",
    "plt.title(\"Average Completion by Block Type\")\n",
    "plt.show()\n",
    "\n",
    "print(iqr_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Completion': BlockType\n",
       " D     91.542969\n",
       " ND    96.158312\n",
       " Name: completion, dtype: float64,\n",
       " 'Std Deviation': BlockType\n",
       " D     6.417297\n",
       " ND    5.210947\n",
       " Name: completion, dtype: float64,\n",
       " 'Wilcoxon Test Statistic': [np.float64(29.0)],\n",
       " 'Wilcoxon P-Value': [np.float64(0.0016002655029296875)],\n",
       " 'Effect Size (r)': [np.float64(0.4320223989133355)]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>BlockType</th>\n",
       "      <th>completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ND</td>\n",
       "      <td>96.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>88.307292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>ND</td>\n",
       "      <td>98.151042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>D</td>\n",
       "      <td>93.411458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>D</td>\n",
       "      <td>90.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>ND</td>\n",
       "      <td>99.401042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>D</td>\n",
       "      <td>91.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>ND</td>\n",
       "      <td>90.325521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>D</td>\n",
       "      <td>85.963542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>8</td>\n",
       "      <td>D</td>\n",
       "      <td>86.432292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>D</td>\n",
       "      <td>83.567708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>9</td>\n",
       "      <td>ND</td>\n",
       "      <td>91.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>D</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11</td>\n",
       "      <td>D</td>\n",
       "      <td>85.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11</td>\n",
       "      <td>ND</td>\n",
       "      <td>82.760417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>12</td>\n",
       "      <td>D</td>\n",
       "      <td>78.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12</td>\n",
       "      <td>ND</td>\n",
       "      <td>90.364583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15</td>\n",
       "      <td>D</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>15</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>D</td>\n",
       "      <td>94.244792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>18</td>\n",
       "      <td>ND</td>\n",
       "      <td>94.557292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>19</td>\n",
       "      <td>D</td>\n",
       "      <td>88.411458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>19</td>\n",
       "      <td>ND</td>\n",
       "      <td>98.854167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>21</td>\n",
       "      <td>D</td>\n",
       "      <td>87.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>21</td>\n",
       "      <td>ND</td>\n",
       "      <td>92.630208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>22</td>\n",
       "      <td>D</td>\n",
       "      <td>81.354167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>22</td>\n",
       "      <td>ND</td>\n",
       "      <td>93.411458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>23</td>\n",
       "      <td>D</td>\n",
       "      <td>91.458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>23</td>\n",
       "      <td>ND</td>\n",
       "      <td>83.489583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>24</td>\n",
       "      <td>D</td>\n",
       "      <td>99.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>24</td>\n",
       "      <td>ND</td>\n",
       "      <td>98.723958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>25</td>\n",
       "      <td>D</td>\n",
       "      <td>99.739583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>25</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>26</td>\n",
       "      <td>D</td>\n",
       "      <td>91.614583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>26</td>\n",
       "      <td>ND</td>\n",
       "      <td>99.036458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>27</td>\n",
       "      <td>D</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>28</td>\n",
       "      <td>D</td>\n",
       "      <td>89.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>28</td>\n",
       "      <td>ND</td>\n",
       "      <td>98.255208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>29</td>\n",
       "      <td>D</td>\n",
       "      <td>96.744792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>29</td>\n",
       "      <td>ND</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>30</td>\n",
       "      <td>D</td>\n",
       "      <td>99.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>30</td>\n",
       "      <td>ND</td>\n",
       "      <td>99.765625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PID BlockType  completion\n",
       "0     1         D   95.000000\n",
       "1     1        ND   96.614583\n",
       "2     2         D   88.307292\n",
       "3     2        ND   98.151042\n",
       "4     3         D   93.411458\n",
       "5     3        ND  100.000000\n",
       "6     4         D   90.833333\n",
       "7     4        ND   99.401042\n",
       "8     6         D   91.458333\n",
       "9     6        ND   90.325521\n",
       "10    7         D   85.963542\n",
       "11    7        ND  100.000000\n",
       "12    8         D   86.432292\n",
       "13    8        ND  100.000000\n",
       "14    9         D   83.567708\n",
       "15    9        ND   91.458333\n",
       "16   10         D  100.000000\n",
       "17   10        ND  100.000000\n",
       "18   11         D   85.078125\n",
       "19   11        ND   82.760417\n",
       "20   12         D   78.281250\n",
       "21   12        ND   90.364583\n",
       "22   15         D  100.000000\n",
       "23   15        ND  100.000000\n",
       "24   18         D   94.244792\n",
       "25   18        ND   94.557292\n",
       "26   19         D   88.411458\n",
       "27   19        ND   98.854167\n",
       "28   21         D   87.083333\n",
       "29   21        ND   92.630208\n",
       "30   22         D   81.354167\n",
       "31   22        ND   93.411458\n",
       "32   23         D   91.458333\n",
       "33   23        ND   83.489583\n",
       "34   24         D   99.296875\n",
       "35   24        ND   98.723958\n",
       "36   25         D   99.739583\n",
       "37   25        ND  100.000000\n",
       "38   26         D   91.614583\n",
       "39   26        ND   99.036458\n",
       "40   27         D  100.000000\n",
       "41   27        ND  100.000000\n",
       "42   28         D   89.062500\n",
       "43   28        ND   98.255208\n",
       "44   29         D   96.744792\n",
       "45   29        ND  100.000000\n",
       "46   30         D   99.687500\n",
       "47   30        ND   99.765625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
